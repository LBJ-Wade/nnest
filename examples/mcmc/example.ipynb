{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example notebook showing how to use the Ensemble sampler (currently in development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "from getdist import plots, MCSamples\n",
    "import getdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "import emcee\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.realpath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.insert(0, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnest import MCMCSampler\n",
    "from nnest.likelihoods import *\n",
    "from nnest.priors import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood\n",
    "#like = Himmelblau(2)\n",
    "#prior = UniformPrior(2, -5, 5)\n",
    "#like = Rosenbrock(2)\n",
    "#prior = UniformPrior(2, -2, 10)\n",
    "#like = Gaussian(2, 0.9)\n",
    "#prior = UniformPrior(2, -5, 5)\n",
    "#like = Eggbox(2)\n",
    "#prior = UniformPrior(2, -15, 15)\n",
    "#like = GaussianShell(2)\n",
    "#prior = UniformPrior(2, -3, 3)\n",
    "#like = GaussianMix(2)\n",
    "#prior = UniformPrior(2, -8, 8)\n",
    "like = DoubleGaussianShell(2, centers=[[-4.0, 0.0], [4.0, 0.0]], weights=[0.5, 1.0])\n",
    "prior = UniformPrior(2, [-7, -3], [7, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory for new run logs/test/run12\n",
      "[nnest.trainer] [INFO] SingleSpeedSpline(\n",
      "  (flow): NormalizingFlow(\n",
      "    (flows): ModuleList(\n",
      "      (0): ActNorm()\n",
      "      (1): Invertible1x1Conv()\n",
      "      (2): NSF_CL(\n",
      "        (f1): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=23, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (f2): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=23, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): ActNorm()\n",
      "      (4): Invertible1x1Conv()\n",
      "      (5): NSF_CL(\n",
      "        (f1): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=23, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (f2): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=23, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): ActNorm()\n",
      "      (7): Invertible1x1Conv()\n",
      "      (8): NSF_CL(\n",
      "        (f1): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=23, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (f2): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=23, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[nnest.trainer] [INFO] Number of network params: [5844]\n",
      "[nnest.trainer] [INFO] Device [cpu]\n",
      "[nnest.sampler] [INFO] Num base params [2]\n",
      "[nnest.sampler] [INFO] Num derived params [0]\n",
      "[nnest.sampler] [INFO] Total params [2]\n"
     ]
    }
   ],
   "source": [
    "sampler = MCMCSampler(like.x_dim, like, flow='spline', prior=prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] Initial acceptance [0.2470]\n",
      "[nnest.trainer] [INFO] Number of training samples [200]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0100]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0333] validation loss [0.1509]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [0.0100] validation loss [0.0791]\n",
      "[nnest.trainer] [INFO] Epoch [134] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [84] validation loss [0.0720] train time (s) [7.6039]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adammoss/opt/anaconda3/envs/nnest/lib/python3.8/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lnpdiff = f + nlp - state.log_prob[j]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] Acceptance [0.4281] min ESS [0.3388] max ESS [1.0527] average jump [0.3863]\n",
      "Removed no burn in\n",
      "[nnest.trainer] [INFO] Number of training samples [415]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0100]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0313] validation loss [0.0516]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [0.0074] validation loss [0.0130]\n",
      "[nnest.trainer] [INFO] Epoch [200] train loss [0.0069] validation loss [0.0194]\n",
      "[nnest.trainer] [INFO] Epoch [219] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [169] validation loss [0.0082] train time (s) [22.4287]]\n",
      "[nnest.sampler] [INFO] Step [100] acceptance [0.2620] min ESS [3.0592] max ESS [11.3017] average jump [1.0501]\n",
      "[nnest.sampler] [INFO] Step [200] acceptance [0.2570] min ESS [5.6862] max ESS [17.3429] average jump [1.0287]\n",
      "[nnest.sampler] [INFO] Step [300] acceptance [0.2580] min ESS [9.4213] max ESS [25.2007] average jump [1.0042]\n",
      "[nnest.sampler] [INFO] Step [400] acceptance [0.2560] min ESS [11.9114] max ESS [33.1451] average jump [0.9654]\n",
      "[nnest.sampler] [INFO] Step [500] acceptance [0.2816] min ESS [14.2031] max ESS [41.6877] average jump [1.0421]\n",
      "[nnest.sampler] [INFO] Step [600] acceptance [0.2877] min ESS [14.7124] max ESS [53.6109] average jump [1.0696]\n"
     ]
    }
   ],
   "source": [
    "sampler.run(2000, 5, bootstrap_iters=1, bootstrap_num_walkers=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like.num_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "for i in range(1):\n",
    "    plt.plot(sampler.samples[i,:,0], sampler.samples[i,:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(like.x_dim, 1, figsize=(10, like.x_dim), sharex=True)\n",
    "for i in range(like.x_dim):\n",
    "    ax[i].plot(sampler.samples[0,:,i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_samples = sampler.samples[:,50:,:]\n",
    "flat_samples = flat_samples.reshape((-1, flat_samples.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(flat_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MCSamples(samples=[sampler.samples[i, :, :].squeeze() for i in range(sampler.samples.shape[0])], \n",
    "               loglikes=[-sampler.loglikes[i, :].squeeze() for i in range(sampler.loglikes.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mc.getEffectiveSamples())\n",
    "print(mc.getMargeStats())\n",
    "print(mc.getConvergeTests())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plots.getSubplotPlotter(width_inch=8)\n",
    "g.triangle_plot(mc, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
