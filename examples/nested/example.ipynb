{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example notebook showing how to use the nested sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "from getdist import plots, MCSamples\n",
    "import getdist\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.realpath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.insert(0, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnest import NestedSampler\n",
    "from nnest.likelihoods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood + prior\n",
    "#like = Himmelblau(2)\n",
    "#transform = lambda x: 5*x\n",
    "like = Rosenbrock(10)\n",
    "transform = lambda x: 5*x\n",
    "#like = Gaussian(2, 0.9)\n",
    "#transform = lambda x: 3*x\n",
    "#like = Eggbox(2)\n",
    "#transform = lambda x: 5*np.pi*x\n",
    "#like = GaussianShell(2)\n",
    "#transform = lambda x: 5*x\n",
    "#like = GaussianMix(2)\n",
    "#transform = lambda x: 5*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory for new run logs/test/run12\n",
      "[nnest.trainer] [INFO] SingleSpeedSpline(\n",
      "  (flow): NormalizingFlow(\n",
      "    (flows): ModuleList(\n",
      "      (0): ActNorm()\n",
      "      (1): Invertible1x1Conv()\n",
      "      (2): NSF_CL(\n",
      "        (f1): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (f2): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): ActNorm()\n",
      "      (4): Invertible1x1Conv()\n",
      "      (5): NSF_CL(\n",
      "        (f1): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (f2): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): ActNorm()\n",
      "      (7): Invertible1x1Conv()\n",
      "      (8): NSF_CL(\n",
      "        (f1): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (f2): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[nnest.trainer] [INFO] Number of network params: [16260]\n",
      "[nnest.trainer] [INFO] Device [cpu]\n",
      "[nnest.sampler] [INFO] Num base params [10]\n",
      "[nnest.sampler] [INFO] Num derived params [0]\n",
      "[nnest.sampler] [INFO] Total params [10]\n",
      "[nnest.sampler] [INFO] Num live points [1000]\n"
     ]
    }
   ],
   "source": [
    "sampler = NestedSampler(like.x_dim, like, transform=transform, num_live_points=1000, hidden_dim=16, num_blocks=3, flow='spline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] MCMC steps [50]\n",
      "[nnest.sampler] [INFO] Initial scale [0.6325]\n",
      "[nnest.sampler] [INFO] Volume switch [-1.0000]\n",
      "[nnest.sampler] [INFO] Step [0] loglstar [-3.4043e+05] max logl [-8.3394e+03] logz [-3.4044e+05] vol [1.00000e+00] ncalls [1001] mean calls [0.0000]\n",
      "[nnest.sampler] [INFO] Step [200] loglstar [-1.6951e+05] max logl [-4.4316e+03] logz [-1.6952e+05] vol [8.18731e-01] ncalls [1217] mean calls [1.1000]\n",
      "[nnest.sampler] [INFO] Step [400] loglstar [-1.3931e+05] max logl [-4.4316e+03] logz [-1.3932e+05] vol [6.70320e-01] ncalls [1490] mean calls [1.5500]\n",
      "[nnest.sampler] [INFO] Step [600] loglstar [-1.2064e+05] max logl [-4.4316e+03] logz [-1.2065e+05] vol [5.48812e-01] ncalls [1818] mean calls [1.7000]\n",
      "[nnest.sampler] [INFO] Step [800] loglstar [-1.0604e+05] max logl [-4.4316e+03] logz [-1.0605e+05] vol [4.49329e-01] ncalls [2247] mean calls [3.3500]\n",
      "[nnest.sampler] [INFO] Step [1000] loglstar [-9.5362e+04] max logl [-4.4316e+03] logz [-9.5370e+04] vol [3.67879e-01] ncalls [2734] mean calls [3.0000]\n",
      "[nnest.sampler] [INFO] Step [1200] loglstar [-8.5577e+04] max logl [-4.4316e+03] logz [-8.5585e+04] vol [3.01194e-01] ncalls [3340] mean calls [3.2500]\n",
      "[nnest.sampler] [INFO] Step [1400] loglstar [-7.6817e+04] max logl [-4.1772e+03] logz [-7.6825e+04] vol [2.46597e-01] ncalls [4115] mean calls [3.7000]\n",
      "[nnest.sampler] [INFO] Step [1600] loglstar [-6.9720e+04] max logl [-4.1772e+03] logz [-6.9729e+04] vol [2.01897e-01] ncalls [5104] mean calls [4.7000]\n",
      "[nnest.sampler] [INFO] Step [1800] loglstar [-6.4088e+04] max logl [-4.1772e+03] logz [-6.4096e+04] vol [1.65299e-01] ncalls [6317] mean calls [5.1000]\n",
      "[nnest.sampler] [INFO] Step [2000] loglstar [-5.8252e+04] max logl [-4.1772e+03] logz [-5.8261e+04] vol [1.35335e-01] ncalls [7716] mean calls [7.2000]\n",
      "[nnest.sampler] [INFO] Step [2200] loglstar [-5.3273e+04] max logl [-5.7537e+02] logz [-5.3282e+04] vol [1.10803e-01] ncalls [9443] mean calls [7.6500]\n",
      "[nnest.sampler] [INFO] Step [2400] loglstar [-4.8915e+04] max logl [-5.7537e+02] logz [-4.8924e+04] vol [9.07180e-02] ncalls [11390] mean calls [9.9500]\n",
      "[nnest.sampler] [INFO] Step [2600] loglstar [-4.4749e+04] max logl [-5.7537e+02] logz [-4.4758e+04] vol [7.42736e-02] ncalls [14443] mean calls [15.4500]\n",
      "[nnest.sampler] [INFO] Step [2800] loglstar [-4.1107e+04] max logl [-5.7537e+02] logz [-4.1117e+04] vol [6.08101e-02] ncalls [17638] mean calls [14.2000]\n",
      "[nnest.sampler] [INFO] Step [3000] loglstar [-3.7606e+04] max logl [-5.7537e+02] logz [-3.7616e+04] vol [4.97871e-02] ncalls [21645] mean calls [19.9000]\n",
      "[nnest.sampler] [INFO] Step [3200] loglstar [-3.4490e+04] max logl [-5.7537e+02] logz [-3.4501e+04] vol [4.07622e-02] ncalls [26926] mean calls [34.9500]\n",
      "[nnest.sampler] [INFO] Step [3400] loglstar [-3.1896e+04] max logl [-5.7537e+02] logz [-3.1906e+04] vol [3.33733e-02] ncalls [33439] mean calls [34.9500]\n",
      "[nnest.sampler] [INFO] Rejection prior no longer efficient, switching sampling method\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0687]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0536] validation loss [0.0489]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [0.0369] validation loss [0.0473]\n",
      "[nnest.trainer] [INFO] Epoch [144] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [94] validation loss [0.0464] train time (s) [43.4029]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5400] min ESS [1.7980] max ESS [8.7164] average jump [0.1514]\n",
      "[nnest.sampler] [INFO] Step [3600] loglstar [-2.9466e+04] maxlogl [-5.7537e+02] logz [-2.9476e+04] vol [2.73237e-02] ncalls [40590] scale [0.1935]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5180] min ESS [2.6492] max ESS [5.6713] average jump [0.1725]\n",
      "[nnest.sampler] [INFO] Step [3800] loglstar [-2.7142e+04] maxlogl [-5.7537e+02] logz [-2.7152e+04] vol [2.23708e-02] ncalls [47415] scale [0.2887]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0650]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0393] validation loss [0.0346]\n",
      "[nnest.trainer] [INFO] Epoch [52] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [2] validation loss [0.0335] train time (s) [15.8379]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5080] min ESS [2.1585] max ESS [5.4521] average jump [0.1466]\n",
      "[nnest.sampler] [INFO] Step [4000] loglstar [-2.5070e+04] maxlogl [-5.7537e+02] logz [-2.5081e+04] vol [1.83156e-02] ncalls [54536] scale [0.4255]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5500] min ESS [1.9682] max ESS [5.2675] average jump [0.1219]\n",
      "[nnest.sampler] [INFO] Step [4200] loglstar [-2.3063e+04] maxlogl [-5.7537e+02] logz [-2.3074e+04] vol [1.49956e-02] ncalls [61227] scale [0.2558]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6020] min ESS [2.6469] max ESS [13.7816] average jump [0.1611]\n",
      "[nnest.sampler] [INFO] Step [4400] loglstar [-2.1297e+04] maxlogl [-5.7537e+02] logz [-2.1308e+04] vol [1.22773e-02] ncalls [68047] scale [0.2437]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5040] min ESS [2.4572] max ESS [6.7500] average jump [0.1485]\n",
      "[nnest.sampler] [INFO] Step [4600] loglstar [-1.9485e+04] maxlogl [-5.7537e+02] logz [-1.9496e+04] vol [1.00518e-02] ncalls [74726] scale [0.2814]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5260] min ESS [1.9673] max ESS [9.3597] average jump [0.1483]\n",
      "[nnest.sampler] [INFO] Step [4800] loglstar [-1.7839e+04] maxlogl [-5.7537e+02] logz [-1.7851e+04] vol [8.22975e-03] ncalls [81580] scale [0.1261]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0591]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0329] validation loss [0.0305]\n",
      "[nnest.trainer] [INFO] Epoch [73] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [23] validation loss [0.0290] train time (s) [22.6679]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5220] min ESS [1.6715] max ESS [6.7778] average jump [0.1263]\n",
      "[nnest.sampler] [INFO] Step [5000] loglstar [-1.6437e+04] maxlogl [-5.7537e+02] logz [-1.6449e+04] vol [6.73795e-03] ncalls [88408] scale [0.3156]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5360] min ESS [1.6070] max ESS [12.4506] average jump [0.1456]\n",
      "[nnest.sampler] [INFO] Step [5200] loglstar [-1.5162e+04] maxlogl [-5.7537e+02] logz [-1.5174e+04] vol [5.51656e-03] ncalls [95266] scale [0.3519]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5600] min ESS [3.0585] max ESS [9.1847] average jump [0.1486]\n",
      "[nnest.sampler] [INFO] Step [5400] loglstar [-1.3907e+04] maxlogl [-5.7537e+02] logz [-1.3919e+04] vol [4.51658e-03] ncalls [102151] scale [0.1895]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4500] min ESS [2.6710] max ESS [8.1074] average jump [0.1456]\n",
      "[nnest.sampler] [INFO] Step [5600] loglstar [-1.2700e+04] maxlogl [-5.7537e+02] logz [-1.2713e+04] vol [3.69786e-03] ncalls [109071] scale [0.3389]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4980] min ESS [3.1439] max ESS [12.7023] average jump [0.1673]\n",
      "[nnest.sampler] [INFO] Step [5800] loglstar [-1.1732e+04] maxlogl [-5.7537e+02] logz [-1.1745e+04] vol [3.02755e-03] ncalls [116425] scale [0.2131]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0527]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0222] validation loss [0.0182]\n",
      "[nnest.trainer] [INFO] Epoch [52] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [2] validation loss [0.0177] train time (s) [16.6478]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5560] min ESS [2.1138] max ESS [10.2367] average jump [0.1446]\n",
      "[nnest.sampler] [INFO] Step [6000] loglstar [-1.0801e+04] maxlogl [-5.7537e+02] logz [-1.0814e+04] vol [2.47875e-03] ncalls [123445] scale [0.1251]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5740] min ESS [1.8565] max ESS [13.4599] average jump [0.1500]\n",
      "[nnest.sampler] [INFO] Step [6200] loglstar [-9.9372e+03] maxlogl [-5.7537e+02] logz [-9.9496e+03] vol [2.02943e-03] ncalls [130604] scale [0.1893]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6140] min ESS [1.9271] max ESS [9.6702] average jump [0.1150]\n",
      "[nnest.sampler] [INFO] Step [6400] loglstar [-9.1456e+03] maxlogl [-5.7537e+02] logz [-9.1587e+03] vol [1.66156e-03] ncalls [137567] scale [0.2847]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5220] min ESS [1.7976] max ESS [6.3887] average jump [0.1070]\n",
      "[nnest.sampler] [INFO] Step [6600] loglstar [-8.4695e+03] maxlogl [-5.7537e+02] logz [-8.4824e+03] vol [1.36037e-03] ncalls [144985] scale [0.1967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] Acceptance [0.4740] min ESS [3.0938] max ESS [13.4122] average jump [0.1471]\n",
      "[nnest.sampler] [INFO] Step [6800] loglstar [-7.8242e+03] maxlogl [-5.7537e+02] logz [-7.8379e+03] vol [1.11378e-03] ncalls [152107] scale [0.1802]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0477]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0126] validation loss [0.0092]\n",
      "[nnest.trainer] [INFO] Epoch [74] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [24] validation loss [0.0068] train time (s) [22.0406]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5400] min ESS [3.0289] max ESS [5.0072] average jump [0.1016]\n",
      "[nnest.sampler] [INFO] Step [7000] loglstar [-7.1897e+03] maxlogl [-5.7537e+02] logz [-7.2033e+03] vol [9.11882e-04] ncalls [159260] scale [0.1852]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5400] min ESS [2.7576] max ESS [6.0841] average jump [0.1146]\n",
      "[nnest.sampler] [INFO] Step [7200] loglstar [-6.6665e+03] maxlogl [-5.7537e+02] logz [-6.6806e+03] vol [7.46586e-04] ncalls [166785] scale [0.3212]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4960] min ESS [1.5988] max ESS [10.7875] average jump [0.1175]\n",
      "[nnest.sampler] [INFO] Step [7400] loglstar [-6.1561e+03] maxlogl [-5.7537e+02] logz [-6.1704e+03] vol [6.11253e-04] ncalls [173892] scale [0.1209]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5640] min ESS [4.2498] max ESS [7.8866] average jump [0.1287]\n",
      "[nnest.sampler] [INFO] Step [7600] loglstar [-5.7188e+03] maxlogl [-5.7537e+02] logz [-5.7328e+03] vol [5.00451e-04] ncalls [181038] scale [0.3182]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6120] min ESS [1.7785] max ESS [11.2745] average jump [0.1060]\n",
      "[nnest.sampler] [INFO] Step [7800] loglstar [-5.3637e+03] maxlogl [-5.7537e+02] logz [-5.3773e+03] vol [4.09735e-04] ncalls [188272] scale [0.2225]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0438]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0016] validation loss [-0.0017]\n",
      "[nnest.trainer] [INFO] Epoch [53] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [3] validation loss [-0.0019] train time (s) [17.0044]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5100] min ESS [2.5243] max ESS [14.1277] average jump [0.1027]\n",
      "[nnest.sampler] [INFO] Step [8000] loglstar [-4.9859e+03] maxlogl [-5.7537e+02] logz [-5.0006e+03] vol [3.35463e-04] ncalls [195577] scale [0.4794]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5120] min ESS [2.2512] max ESS [9.2797] average jump [0.1395]\n",
      "[nnest.sampler] [INFO] Step [8200] loglstar [-4.5863e+03] maxlogl [-3.5741e+02] logz [-4.6009e+03] vol [2.74654e-04] ncalls [202663] scale [0.3504]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4960] min ESS [1.8656] max ESS [10.5003] average jump [0.1166]\n",
      "[nnest.sampler] [INFO] Step [8400] loglstar [-4.2586e+03] maxlogl [-3.5741e+02] logz [-4.2735e+03] vol [2.24867e-04] ncalls [209911] scale [0.2656]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4960] min ESS [1.6869] max ESS [11.7136] average jump [0.1191]\n",
      "[nnest.sampler] [INFO] Step [8600] loglstar [-3.9219e+03] maxlogl [-3.5741e+02] logz [-3.9372e+03] vol [1.84106e-04] ncalls [217231] scale [0.2129]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4900] min ESS [4.3218] max ESS [17.0453] average jump [0.1283]\n",
      "[nnest.sampler] [INFO] Step [8800] loglstar [-3.6704e+03] maxlogl [-3.5741e+02] logz [-3.6856e+03] vol [1.50733e-04] ncalls [224428] scale [0.2774]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0397]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0060] validation loss [-0.0109]\n",
      "[nnest.trainer] [INFO] Epoch [75] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [25] validation loss [-0.0129] train time (s) [25.6589]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5300] min ESS [2.9170] max ESS [14.2185] average jump [0.1112]\n",
      "[nnest.sampler] [INFO] Step [9000] loglstar [-3.3603e+03] maxlogl [-3.5741e+02] logz [-3.3761e+03] vol [1.23410e-04] ncalls [231793] scale [0.2249]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5080] min ESS [3.1631] max ESS [7.9466] average jump [0.1125]\n",
      "[nnest.sampler] [INFO] Step [9200] loglstar [-3.1232e+03] maxlogl [-3.4498e+02] logz [-3.1385e+03] vol [1.01039e-04] ncalls [238904] scale [0.2203]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4420] min ESS [4.7358] max ESS [12.9905] average jump [0.1196]\n",
      "[nnest.sampler] [INFO] Step [9400] loglstar [-2.9161e+03] maxlogl [-3.4498e+02] logz [-2.9320e+03] vol [8.27241e-05] ncalls [246439] scale [0.2257]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5600] min ESS [1.7573] max ESS [9.4916] average jump [0.0958]\n",
      "[nnest.sampler] [INFO] Step [9600] loglstar [-2.6893e+03] maxlogl [-3.4498e+02] logz [-2.7052e+03] vol [6.77287e-05] ncalls [253585] scale [0.2647]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6300] min ESS [1.8050] max ESS [20.0010] average jump [0.0925]\n",
      "[nnest.sampler] [INFO] Step [9800] loglstar [-2.5222e+03] maxlogl [-3.4498e+02] logz [-2.5384e+03] vol [5.54516e-05] ncalls [260946] scale [0.3949]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0356]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0181] validation loss [-0.0217]\n",
      "[nnest.trainer] [INFO] Epoch [78] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [28] validation loss [-0.0236] train time (s) [25.8887]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5760] min ESS [3.0537] max ESS [14.8460] average jump [0.1122]\n",
      "[nnest.sampler] [INFO] Step [10000] loglstar [-2.3455e+03] maxlogl [-3.4498e+02] logz [-2.3621e+03] vol [4.53999e-05] ncalls [268295] scale [0.3210]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [2.9230] max ESS [8.1034] average jump [0.0950]\n",
      "[nnest.sampler] [INFO] Step [10200] loglstar [-2.1768e+03] maxlogl [-3.4498e+02] logz [-2.1930e+03] vol [3.71703e-05] ncalls [275235] scale [0.1265]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5140] min ESS [3.6600] max ESS [12.6781] average jump [0.1065]\n",
      "[nnest.sampler] [INFO] Step [10400] loglstar [-2.0373e+03] maxlogl [-2.9457e+02] logz [-2.0534e+03] vol [3.04325e-05] ncalls [282468] scale [0.1674]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5500] min ESS [4.5028] max ESS [12.2156] average jump [0.1021]\n",
      "[nnest.sampler] [INFO] Step [10600] loglstar [-1.9056e+03] maxlogl [-2.9457e+02] logz [-1.9224e+03] vol [2.49160e-05] ncalls [289551] scale [0.1880]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5180] min ESS [2.4073] max ESS [13.5900] average jump [0.0939]\n",
      "[nnest.sampler] [INFO] Step [10800] loglstar [-1.7812e+03] maxlogl [-2.9457e+02] logz [-1.7984e+03] vol [2.03995e-05] ncalls [296689] scale [0.4437]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0324]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0286] validation loss [-0.0327]\n",
      "[nnest.trainer] [INFO] Epoch [51] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [1] validation loss [-0.0327] train time (s) [15.1907]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5980] min ESS [3.7618] max ESS [11.2314] average jump [0.0998]\n",
      "[nnest.sampler] [INFO] Step [11000] loglstar [-1.6482e+03] maxlogl [-2.9457e+02] logz [-1.6646e+03] vol [1.67017e-05] ncalls [303957] scale [0.2823]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4320] min ESS [4.1795] max ESS [9.1279] average jump [0.0745]\n",
      "[nnest.sampler] [INFO] Step [11200] loglstar [-1.5343e+03] maxlogl [-2.5835e+02] logz [-1.5514e+03] vol [1.36742e-05] ncalls [311533] scale [0.2313]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6700] min ESS [4.5626] max ESS [7.7823] average jump [0.0756]\n",
      "[nnest.sampler] [INFO] Step [11400] loglstar [-1.4298e+03] maxlogl [-2.5835e+02] logz [-1.4469e+03] vol [1.11955e-05] ncalls [318791] scale [0.3296]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5260] min ESS [3.5202] max ESS [16.2391] average jump [0.0818]\n",
      "[nnest.sampler] [INFO] Step [11600] loglstar [-1.3452e+03] maxlogl [-1.9637e+02] logz [-1.3619e+03] vol [9.16609e-06] ncalls [326266] scale [0.1813]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5320] min ESS [3.4577] max ESS [9.7341] average jump [0.0766]\n",
      "[nnest.sampler] [INFO] Step [11800] loglstar [-1.2662e+03] maxlogl [-1.6848e+02] logz [-1.2834e+03] vol [7.50456e-06] ncalls [333799] scale [0.1288]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0355] validation loss [-0.0372]\n",
      "[nnest.trainer] [INFO] Epoch [52] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [2] validation loss [-0.0388] train time (s) [16.6735]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5560] min ESS [4.6382] max ESS [10.8460] average jump [0.0895]\n",
      "[nnest.sampler] [INFO] Step [12000] loglstar [-1.1921e+03] maxlogl [-1.6848e+02] logz [-1.2099e+03] vol [6.14421e-06] ncalls [341279] scale [0.1256]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5120] min ESS [2.8650] max ESS [13.0121] average jump [0.0767]\n",
      "[nnest.sampler] [INFO] Step [12200] loglstar [-1.1147e+03] maxlogl [-1.4334e+02] logz [-1.1324e+03] vol [5.03046e-06] ncalls [348883] scale [0.3934]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4400] min ESS [3.7036] max ESS [22.5429] average jump [0.0857]\n",
      "[nnest.sampler] [INFO] Step [12400] loglstar [-1.0437e+03] maxlogl [-1.4334e+02] logz [-1.0621e+03] vol [4.11859e-06] ncalls [356259] scale [0.5156]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5560] min ESS [2.5557] max ESS [9.3914] average jump [0.0698]\n",
      "[nnest.sampler] [INFO] Step [12600] loglstar [-9.8594e+02] maxlogl [-1.4334e+02] logz [-1.0040e+03] vol [3.37202e-06] ncalls [363682] scale [0.2622]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5920] min ESS [2.7129] max ESS [13.0421] average jump [0.0670]\n",
      "[nnest.sampler] [INFO] Step [12800] loglstar [-9.2556e+02] maxlogl [-1.4334e+02] logz [-9.4333e+02] vol [2.76077e-06] ncalls [371166] scale [0.1941]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0269]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0455] validation loss [-0.0444]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.0570] validation loss [-0.0471]\n",
      "[nnest.trainer] [INFO] Epoch [146] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [96] validation loss [-0.0486] train time (s) [53.5242]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4820] min ESS [3.7371] max ESS [15.8647] average jump [0.0739]\n",
      "[nnest.sampler] [INFO] Step [13000] loglstar [-8.6272e+02] maxlogl [-1.4334e+02] logz [-8.8105e+02] vol [2.26033e-06] ncalls [379032] scale [0.3816]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4940] min ESS [7.5777] max ESS [17.5967] average jump [0.0853]\n",
      "[nnest.sampler] [INFO] Step [13200] loglstar [-8.0921e+02] maxlogl [-1.4334e+02] logz [-8.2766e+02] vol [1.85060e-06] ncalls [385977] scale [0.3009]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5320] min ESS [3.2339] max ESS [18.9349] average jump [0.0779]\n",
      "[nnest.sampler] [INFO] Step [13400] loglstar [-7.6097e+02] maxlogl [-1.3273e+02] logz [-7.7971e+02] vol [1.51514e-06] ncalls [393097] scale [0.1108]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5420] min ESS [4.1218] max ESS [15.4179] average jump [0.0778]\n",
      "[nnest.sampler] [INFO] Step [13600] loglstar [-7.1312e+02] maxlogl [-1.1433e+02] logz [-7.3180e+02] vol [1.24050e-06] ncalls [400169] scale [0.2105]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5840] min ESS [4.9017] max ESS [12.5153] average jump [0.0726]\n",
      "[nnest.sampler] [INFO] Step [13800] loglstar [-6.7306e+02] maxlogl [-1.1433e+02] logz [-6.9269e+02] vol [1.01563e-06] ncalls [407158] scale [0.2269]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0242]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0578] validation loss [-0.0627]\n",
      "[nnest.trainer] [INFO] Epoch [80] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [30] validation loss [-0.0632] train time (s) [27.4199]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5220] min ESS [4.3319] max ESS [17.6181] average jump [0.0666]\n",
      "[nnest.sampler] [INFO] Step [14000] loglstar [-6.3649e+02] maxlogl [-1.1433e+02] logz [-6.5542e+02] vol [8.31529e-07] ncalls [414276] scale [0.1211]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5240] min ESS [4.6258] max ESS [24.8017] average jump [0.0713]\n",
      "[nnest.sampler] [INFO] Step [14200] loglstar [-5.9831e+02] maxlogl [-6.6276e+01] logz [-6.1764e+02] vol [6.80798e-07] ncalls [421484] scale [0.2880]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5820] min ESS [5.5767] max ESS [11.3838] average jump [0.0673]\n",
      "[nnest.sampler] [INFO] Step [14400] loglstar [-5.6294e+02] maxlogl [-6.6276e+01] logz [-5.8208e+02] vol [5.57390e-07] ncalls [429088] scale [0.2052]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5680] min ESS [2.8085] max ESS [21.8637] average jump [0.0645]\n",
      "[nnest.sampler] [INFO] Step [14600] loglstar [-5.3116e+02] maxlogl [-6.6276e+01] logz [-5.5065e+02] vol [4.56353e-07] ncalls [436407] scale [0.1819]\n"
     ]
    }
   ],
   "source": [
    "sampler.run(strategy=['rejection_prior', 'mcmc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sampler.logz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MCSamples(samples=sampler.samples, weights=sampler.weights, loglikes=-sampler.loglikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mc.getEffectiveSamples())\n",
    "print(mc.getMargeStats())\n",
    "print(mc.likeStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plots.getSubplotPlotter(width_inch=8)\n",
    "g.triangle_plot(mc, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
