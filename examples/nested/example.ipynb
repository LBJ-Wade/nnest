{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "from getdist import plots, MCSamples\n",
    "import getdist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.realpath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.insert(0, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnest import NestedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Himmelblau\n",
    "def loglike(z):\n",
    "    z1 = z[:, 0]\n",
    "    z2 = z[:, 1]\n",
    "    return - (z1**2 + z2 - 11.)**2 - (z1 + z2**2 - 7.)**2\n",
    "def transform(x):\n",
    "    return 5. * x\n",
    "dims = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosenbrock\n",
    "def loglike(z):\n",
    "    return np.array([-sum(100.0 * (x[1:] - x[:-1] ** 2.0) ** 2.0 + (1 - x[:-1]) ** 2.0) for x in z])\n",
    "def transform(x):\n",
    "    return 5. * x\n",
    "dims = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory for new run logs/test/run12\n",
      "[nnest.trainer] [INFO] SingleSpeed(\n",
      "  (net): FlowSequential(\n",
      "    (0): CouplingLayer(\n",
      "      (scale_net): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): Tanh()\n",
      "        (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "      )\n",
      "      (translate_net): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): CouplingLayer(\n",
      "      (scale_net): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): Tanh()\n",
      "        (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "      )\n",
      "      (translate_net): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): CouplingLayer(\n",
      "      (scale_net): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): Tanh()\n",
      "        (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "      )\n",
      "      (translate_net): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): CouplingLayer(\n",
      "      (scale_net): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): Tanh()\n",
      "        (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "      )\n",
      "      (translate_net): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (4): CouplingLayer(\n",
      "      (scale_net): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): Tanh()\n",
      "        (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "      )\n",
      "      (translate_net): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[nnest.trainer] [INFO] Device [cpu]\n",
      "[nnest.sampler] [INFO] Num base params [4]\n",
      "[nnest.sampler] [INFO] Num derived params [0]\n",
      "[nnest.sampler] [INFO] Total params [4]\n",
      "[nnest.sampler] [INFO] Num live points [1000]\n"
     ]
    }
   ],
   "source": [
    "sampler = NestedSampler(dims, loglike, transform=transform, num_live_points=1000, hidden_dim=128, num_layers=1, num_blocks=5, scale='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] MCMC steps [20]\n",
      "[nnest.sampler] [INFO] Initial scale [1.0000]\n",
      "[nnest.sampler] [INFO] Volume switch [-1.0000]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0227]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0404] validation loss [0.0372]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [0.0327] validation loss [0.0325]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [0.0311] validation loss [0.0312]\n",
      "[nnest.trainer] [INFO] Epoch [150] train loss [0.0301] validation loss [0.0304]\n",
      "[nnest.trainer] [INFO] Epoch [200] train loss [0.0297] validation loss [0.0302]\n",
      "[nnest.trainer] [INFO] Epoch [250] train loss [0.0293] validation loss [0.0301]\n",
      "[nnest.trainer] [INFO] Epoch [296] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [246] validation loss [0.0299]\n",
      "[nnest.sampler] [INFO] Step [0] loglstar [-1.8551e+05] max logl [-5.1325e+01] logz [-1.8552e+05] vol [1.00000e+00] ncalls [1001] mean calls [1.0000]\n",
      "[nnest.sampler] [INFO] Step [200] loglstar [-6.6772e+04] max logl [-4.8430e+01] logz [-6.6779e+04] vol [8.18731e-01] ncalls [1228] mean calls [1.2000]\n",
      "[nnest.sampler] [INFO] Step [400] loglstar [-5.0276e+04] max logl [-4.8430e+01] logz [-5.0284e+04] vol [6.70320e-01] ncalls [1501] mean calls [1.6000]\n",
      "[nnest.sampler] [INFO] Step [600] loglstar [-3.8982e+04] max logl [-4.8430e+01] logz [-3.8989e+04] vol [5.48812e-01] ncalls [1817] mean calls [1.3000]\n",
      "[nnest.sampler] [INFO] Step [800] loglstar [-2.9628e+04] max logl [-4.8430e+01] logz [-2.9636e+04] vol [4.49329e-01] ncalls [2216] mean calls [2.6000]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0177]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0251] validation loss [0.0217]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [0.0195] validation loss [0.0200]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [0.0189] validation loss [0.0199]\n",
      "[nnest.trainer] [INFO] Epoch [150] train loss [0.0186] validation loss [0.0198]\n",
      "[nnest.trainer] [INFO] Epoch [200] train loss [0.0183] validation loss [0.0199]\n",
      "[nnest.trainer] [INFO] Epoch [223] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [173] validation loss [0.0195]\n",
      "[nnest.sampler] [INFO] Step [1000] loglstar [-2.2603e+04] max logl [-4.8430e+01] logz [-2.2611e+04] vol [3.67879e-01] ncalls [2707] mean calls [2.5000]\n",
      "[nnest.sampler] [INFO] Step [1200] loglstar [-1.7924e+04] max logl [-4.8430e+01] logz [-1.7932e+04] vol [3.01194e-01] ncalls [3278] mean calls [3.0000]\n",
      "[nnest.sampler] [INFO] Step [1400] loglstar [-1.3575e+04] max logl [-4.8430e+01] logz [-1.3583e+04] vol [2.46597e-01] ncalls [4047] mean calls [4.4000]\n",
      "[nnest.sampler] [INFO] Step [1600] loglstar [-1.0465e+04] max logl [-4.8430e+01] logz [-1.0474e+04] vol [2.01897e-01] ncalls [4922] mean calls [5.2000]\n",
      "[nnest.sampler] [INFO] Step [1800] loglstar [-8.3365e+03] max logl [-4.8430e+01] logz [-8.3452e+03] vol [1.65299e-01] ncalls [6160] mean calls [7.0000]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0139]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0150] validation loss [0.0105]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [0.0088] validation loss [0.0111]\n",
      "[nnest.trainer] [INFO] Epoch [69] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [19] validation loss [0.0102]\n",
      "[nnest.sampler] [INFO] Step [2000] loglstar [-6.6540e+03] max logl [-4.8430e+01] logz [-6.6629e+03] vol [1.35335e-01] ncalls [7380] mean calls [5.6000]\n",
      "[nnest.sampler] [INFO] Step [2200] loglstar [-5.1514e+03] max logl [-4.8430e+01] logz [-5.1605e+03] vol [1.10803e-01] ncalls [8940] mean calls [8.6000]\n",
      "[nnest.sampler] [INFO] Step [2400] loglstar [-4.1080e+03] max logl [-4.8430e+01] logz [-4.1171e+03] vol [9.07180e-02] ncalls [10929] mean calls [7.4000]\n",
      "[nnest.sampler] [INFO] Switching to MCMC sampling\n",
      "[nnest.sampler] [INFO] Acceptance [0.6050] min ESS [2.5825] max ESS [5.1327] average jump distance [0.1496]\n",
      "[nnest.sampler] [INFO] Step [2600] loglstar [-3.2535e+03] maxlogl [-3.2691e+01] logz [-3.2630e+03] vol [7.42736e-02] ncalls [13800] scale [0.2055]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6500] min ESS [3.7604] max ESS [6.2892] average jump distance [0.1572]\n",
      "[nnest.sampler] [INFO] Step [2800] loglstar [-2.6023e+03] maxlogl [-3.2691e+01] logz [-2.6111e+03] vol [6.08101e-02] ncalls [16620] scale [0.6597]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0108]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0045] validation loss [0.0022]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.0006] validation loss [0.0004]\n",
      "[nnest.trainer] [INFO] Epoch [88] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [38] validation loss [0.0003]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4550] min ESS [1.5241] max ESS [12.8501] average jump distance [0.1108]\n",
      "[nnest.sampler] [INFO] Step [3000] loglstar [-2.2141e+03] maxlogl [-3.2691e+01] logz [-2.2232e+03] vol [4.97871e-02] ncalls [19361] scale [0.6024]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5800] min ESS [3.2340] max ESS [9.3225] average jump distance [0.1464]\n",
      "[nnest.sampler] [INFO] Step [3200] loglstar [-1.7970e+03] maxlogl [-1.0103e+01] logz [-1.8061e+03] vol [4.07622e-02] ncalls [21915] scale [1.3015]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4850] min ESS [4.8664] max ESS [8.3489] average jump distance [0.1541]\n",
      "[nnest.sampler] [INFO] Step [3400] loglstar [-1.5016e+03] maxlogl [-1.0103e+01] logz [-1.5108e+03] vol [3.33733e-02] ncalls [24355] scale [0.6548]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [3.3173] max ESS [11.2439] average jump distance [0.1388]\n",
      "[nnest.sampler] [INFO] Step [3600] loglstar [-1.2583e+03] maxlogl [-1.0103e+01] logz [-1.2681e+03] vol [2.73237e-02] ncalls [27146] scale [0.3031]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4700] min ESS [3.7436] max ESS [5.7152] average jump distance [0.1115]\n",
      "[nnest.sampler] [INFO] Step [3800] loglstar [-1.0887e+03] maxlogl [-1.0103e+01] logz [-1.0982e+03] vol [2.23708e-02] ncalls [29865] scale [0.7402]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0086]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0049] validation loss [-0.0081]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.0099] validation loss [-0.0088]\n",
      "[nnest.trainer] [INFO] Epoch [76] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [26] validation loss [-0.0092]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [2.5518] max ESS [6.3575] average jump distance [0.0885]\n",
      "[nnest.sampler] [INFO] Step [4000] loglstar [-9.1685e+02] maxlogl [-1.0103e+01] logz [-9.2752e+02] vol [1.83156e-02] ncalls [32602] scale [0.4131]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4400] min ESS [6.0729] max ESS [9.5594] average jump distance [0.1414]\n",
      "[nnest.sampler] [INFO] Step [4200] loglstar [-7.6737e+02] maxlogl [-1.0103e+01] logz [-7.7718e+02] vol [1.49956e-02] ncalls [35141] scale [0.4527]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5350] min ESS [2.5772] max ESS [5.7661] average jump distance [0.1049]\n",
      "[nnest.sampler] [INFO] Step [4400] loglstar [-6.4953e+02] maxlogl [-7.7649e+00] logz [-6.5937e+02] vol [1.22773e-02] ncalls [37767] scale [0.4149]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4650] min ESS [3.4795] max ESS [11.1517] average jump distance [0.0988]\n",
      "[nnest.sampler] [INFO] Step [4600] loglstar [-5.6481e+02] maxlogl [-4.2868e+00] logz [-5.7579e+02] vol [1.00518e-02] ncalls [40498] scale [0.1986]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6450] min ESS [5.9938] max ESS [11.5673] average jump distance [0.0968]\n",
      "[nnest.sampler] [INFO] Step [4800] loglstar [-4.8215e+02] maxlogl [-4.2868e+00] logz [-4.9234e+02] vol [8.22975e-03] ncalls [43237] scale [0.2856]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0070]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0143] validation loss [-0.0144]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.0191] validation loss [-0.0162]\n",
      "[nnest.trainer] [INFO] Epoch [55] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [5] validation loss [-0.0167]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4800] min ESS [3.7234] max ESS [6.3963] average jump distance [0.0903]\n",
      "[nnest.sampler] [INFO] Step [5000] loglstar [-4.1829e+02] maxlogl [-4.2868e+00] logz [-4.2845e+02] vol [6.73795e-03] ncalls [46042] scale [0.6706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] Acceptance [0.4800] min ESS [5.5592] max ESS [9.8946] average jump distance [0.1087]\n",
      "[nnest.sampler] [INFO] Step [5200] loglstar [-3.6618e+02] maxlogl [-4.2868e+00] logz [-3.7645e+02] vol [5.51656e-03] ncalls [48861] scale [0.3472]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5750] min ESS [3.3524] max ESS [13.6143] average jump distance [0.0945]\n",
      "[nnest.sampler] [INFO] Step [5400] loglstar [-3.1650e+02] maxlogl [-4.2868e+00] logz [-3.2690e+02] vol [4.51658e-03] ncalls [51552] scale [0.3868]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [3.1523] max ESS [13.6320] average jump distance [0.0932]\n",
      "[nnest.sampler] [INFO] Step [5600] loglstar [-2.7773e+02] maxlogl [-4.2868e+00] logz [-2.8821e+02] vol [3.69786e-03] ncalls [54360] scale [0.4562]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5550] min ESS [5.7056] max ESS [8.3327] average jump distance [0.0996]\n",
      "[nnest.sampler] [INFO] Step [5800] loglstar [-2.4086e+02] maxlogl [-4.2868e+00] logz [-2.5218e+02] vol [3.02755e-03] ncalls [57197] scale [0.6140]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0053]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0234] validation loss [-0.0265]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.0286] validation loss [-0.0276]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.0292] validation loss [-0.0276]\n",
      "[nnest.trainer] [INFO] Epoch [150] train loss [-0.0294] validation loss [-0.0280]\n",
      "[nnest.trainer] [INFO] Epoch [200] train loss [-0.0294] validation loss [-0.0275]\n",
      "[nnest.trainer] [INFO] Epoch [249] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [199] validation loss [-0.0280]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4900] min ESS [7.0074] max ESS [14.3697] average jump distance [0.0818]\n",
      "[nnest.sampler] [INFO] Step [6000] loglstar [-2.1133e+02] maxlogl [-3.3123e+00] logz [-2.2214e+02] vol [2.47875e-03] ncalls [60199] scale [0.6145]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5200] min ESS [6.5179] max ESS [12.2817] average jump distance [0.0886]\n",
      "[nnest.sampler] [INFO] Step [6200] loglstar [-1.8268e+02] maxlogl [-3.3123e+00] logz [-1.9369e+02] vol [2.02943e-03] ncalls [62882] scale [0.6464]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5250] min ESS [4.8114] max ESS [8.7207] average jump distance [0.1043]\n",
      "[nnest.sampler] [INFO] Step [6400] loglstar [-1.5637e+02] maxlogl [-3.3123e+00] logz [-1.6789e+02] vol [1.66156e-03] ncalls [65506] scale [0.4210]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5350] min ESS [8.5616] max ESS [13.0049] average jump distance [0.0767]\n",
      "[nnest.sampler] [INFO] Step [6600] loglstar [-1.3704e+02] maxlogl [-3.3123e+00] logz [-1.4779e+02] vol [1.36037e-03] ncalls [68182] scale [0.6852]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5350] min ESS [2.7138] max ESS [13.2234] average jump distance [0.0686]\n",
      "[nnest.sampler] [INFO] Step [6800] loglstar [-1.1817e+02] maxlogl [-3.3123e+00] logz [-1.3035e+02] vol [1.11378e-03] ncalls [71003] scale [0.4152]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0041]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0334] validation loss [-0.0376]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.0382] validation loss [-0.0382]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.0391] validation loss [-0.0386]\n",
      "[nnest.trainer] [INFO] Epoch [150] train loss [-0.0394] validation loss [-0.0388]\n",
      "[nnest.trainer] [INFO] Epoch [200] train loss [-0.0398] validation loss [-0.0390]\n",
      "[nnest.trainer] [INFO] Epoch [250] train loss [-0.0400] validation loss [-0.0391]\n",
      "[nnest.trainer] [INFO] Epoch [300] train loss [-0.0402] validation loss [-0.0388]\n",
      "[nnest.trainer] [INFO] Epoch [345] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [295] validation loss [-0.0392]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5300] min ESS [4.6221] max ESS [16.0623] average jump distance [0.0412]\n",
      "[nnest.sampler] [INFO] Step [7000] loglstar [-1.0172e+02] maxlogl [-3.3123e+00] logz [-1.1300e+02] vol [9.11882e-04] ncalls [73894] scale [0.2107]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [8.5918] max ESS [16.7591] average jump distance [0.0889]\n",
      "[nnest.sampler] [INFO] Step [7200] loglstar [-9.0265e+01] maxlogl [-3.3123e+00] logz [-1.0134e+02] vol [7.46586e-04] ncalls [76408] scale [1.2771]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5800] min ESS [6.5504] max ESS [8.6789] average jump distance [0.0672]\n",
      "[nnest.sampler] [INFO] Step [7400] loglstar [-7.8471e+01] maxlogl [-3.3123e+00] logz [-9.0176e+01] vol [6.11253e-04] ncalls [79063] scale [0.5221]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5850] min ESS [7.5613] max ESS [21.0000] average jump distance [0.0627]\n",
      "[nnest.sampler] [INFO] Step [7600] loglstar [-6.8989e+01] maxlogl [-3.3123e+00] logz [-8.0314e+01] vol [5.00451e-04] ncalls [81897] scale [0.3007]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6050] min ESS [8.6133] max ESS [19.0151] average jump distance [0.0551]\n",
      "[nnest.sampler] [INFO] Step [7800] loglstar [-6.0346e+01] maxlogl [-3.3123e+00] logz [-7.1563e+01] vol [4.09735e-04] ncalls [84740] scale [0.3325]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0032]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0439] validation loss [-0.0461]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.0489] validation loss [-0.0483]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.0493] validation loss [-0.0482]\n",
      "[nnest.trainer] [INFO] Epoch [150] train loss [-0.0499] validation loss [-0.0476]\n",
      "[nnest.trainer] [INFO] Epoch [162] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [112] validation loss [-0.0487]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4300] min ESS [4.2216] max ESS [18.9740] average jump distance [0.0501]\n",
      "[nnest.sampler] [INFO] Step [8000] loglstar [-5.3492e+01] maxlogl [-3.3123e+00] logz [-6.4922e+01] vol [3.35463e-04] ncalls [87584] scale [0.2708]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5350] min ESS [12.4590] max ESS [18.9744] average jump distance [0.0688]\n",
      "[nnest.sampler] [INFO] Step [8200] loglstar [-4.7628e+01] maxlogl [-3.3123e+00] logz [-5.8989e+01] vol [2.74654e-04] ncalls [90367] scale [0.6068]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6800] min ESS [5.3310] max ESS [11.4861] average jump distance [0.0544]\n",
      "[nnest.sampler] [INFO] Step [8400] loglstar [-4.1977e+01] maxlogl [-2.4488e+00] logz [-5.3578e+01] vol [2.24867e-04] ncalls [93182] scale [0.6236]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5350] min ESS [10.5328] max ESS [14.7634] average jump distance [0.0584]\n",
      "[nnest.sampler] [INFO] Step [8600] loglstar [-3.7304e+01] maxlogl [-2.4488e+00] logz [-4.9036e+01] vol [1.84106e-04] ncalls [95955] scale [0.3462]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5400] min ESS [5.1693] max ESS [8.1651] average jump distance [0.0464]\n",
      "[nnest.sampler] [INFO] Step [8800] loglstar [-3.2698e+01] maxlogl [-1.2385e+00] logz [-4.4460e+01] vol [1.50733e-04] ncalls [98999] scale [0.5760]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0025]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0531] validation loss [-0.0563]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.0588] validation loss [-0.0588]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.0592] validation loss [-0.0585]\n",
      "[nnest.trainer] [INFO] Epoch [100] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [50] validation loss [-0.0588]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5200] min ESS [4.2156] max ESS [8.5658] average jump distance [0.0518]\n",
      "[nnest.sampler] [INFO] Step [9000] loglstar [-2.9000e+01] maxlogl [-1.2385e+00] logz [-4.0869e+01] vol [1.23410e-04] ncalls [101918] scale [0.6288]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5650] min ESS [6.0667] max ESS [8.7153] average jump distance [0.0710]\n",
      "[nnest.sampler] [INFO] Step [9200] loglstar [-2.5808e+01] maxlogl [-4.7448e-01] logz [-3.7608e+01] vol [1.01039e-04] ncalls [104618] scale [0.8326]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5750] min ESS [4.3409] max ESS [9.8199] average jump distance [0.0544]\n",
      "[nnest.sampler] [INFO] Step [9400] loglstar [-2.2693e+01] maxlogl [-4.7448e-01] logz [-3.4734e+01] vol [8.27241e-05] ncalls [107480] scale [0.3894]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5500] min ESS [3.2801] max ESS [7.8783] average jump distance [0.0465]\n",
      "[nnest.sampler] [INFO] Step [9600] loglstar [-2.0273e+01] maxlogl [-4.7448e-01] logz [-3.2276e+01] vol [6.77287e-05] ncalls [110309] scale [0.1977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] Acceptance [0.4500] min ESS [5.1380] max ESS [15.1126] average jump distance [0.0489]\n",
      "[nnest.sampler] [INFO] Step [9800] loglstar [-1.8096e+01] maxlogl [-4.7448e-01] logz [-3.0164e+01] vol [5.54516e-05] ncalls [113183] scale [0.4327]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0020]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0624] validation loss [-0.0655]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.0674] validation loss [-0.0684]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.0666] validation loss [-0.0663]\n",
      "[nnest.trainer] [INFO] Epoch [110] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [60] validation loss [-0.0686]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6500] min ESS [3.1657] max ESS [8.4967] average jump distance [0.0367]\n",
      "[nnest.sampler] [INFO] Step [10000] loglstar [-1.6361e+01] maxlogl [-4.7448e-01] logz [-2.8388e+01] vol [4.53999e-05] ncalls [116199] scale [0.4490]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5500] min ESS [10.7845] max ESS [16.0690] average jump distance [0.0486]\n",
      "[nnest.sampler] [INFO] Step [10200] loglstar [-1.4532e+01] maxlogl [-4.7448e-01] logz [-2.6834e+01] vol [3.71703e-05] ncalls [118948] scale [0.4638]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5050] min ESS [4.4057] max ESS [9.6012] average jump distance [0.0518]\n",
      "[nnest.sampler] [INFO] Step [10400] loglstar [-1.2850e+01] maxlogl [-4.7448e-01] logz [-2.5244e+01] vol [3.04325e-05] ncalls [121950] scale [0.2824]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4900] min ESS [6.4390] max ESS [10.2152] average jump distance [0.0663]\n",
      "[nnest.sampler] [INFO] Step [10600] loglstar [-1.1586e+01] maxlogl [-4.7448e-01] logz [-2.3945e+01] vol [2.49160e-05] ncalls [124785] scale [0.3834]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5400] min ESS [4.4334] max ESS [11.2602] average jump distance [0.0546]\n",
      "[nnest.sampler] [INFO] Step [10800] loglstar [-1.0425e+01] maxlogl [-4.7448e-01] logz [-2.2870e+01] vol [2.03995e-05] ncalls [127709] scale [0.2126]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0016]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0725] validation loss [-0.0742]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.0691] validation loss [-0.0688]\n",
      "[nnest.trainer] [INFO] Epoch [77] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [27] validation loss [-0.0774]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6150] min ESS [3.2036] max ESS [8.7801] average jump distance [0.0431]\n",
      "[nnest.sampler] [INFO] Step [11000] loglstar [-9.4532e+00] maxlogl [-4.7448e-01] logz [-2.1930e+01] vol [1.67017e-05] ncalls [130790] scale [0.3447]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5350] min ESS [9.7453] max ESS [12.0251] average jump distance [0.0472]\n",
      "[nnest.sampler] [INFO] Step [11200] loglstar [-8.6475e+00] maxlogl [-4.3746e-01] logz [-2.1132e+01] vol [1.36742e-05] ncalls [133638] scale [0.4625]\n",
      "[nnest.sampler] [INFO] Acceptance [0.7150] min ESS [6.2320] max ESS [7.1554] average jump distance [0.0384]\n",
      "[nnest.sampler] [INFO] Step [11400] loglstar [-7.8606e+00] maxlogl [-2.9076e-01] logz [-2.0446e+01] vol [1.11955e-05] ncalls [136584] scale [0.4106]\n",
      "[nnest.sampler] [INFO] Acceptance [0.3800] min ESS [4.6719] max ESS [11.6397] average jump distance [0.0630]\n",
      "[nnest.sampler] [INFO] Step [11600] loglstar [-7.2656e+00] maxlogl [-2.9076e-01] logz [-1.9847e+01] vol [9.16609e-06] ncalls [139566] scale [0.4088]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5450] min ESS [5.0570] max ESS [7.4091] average jump distance [0.0449]\n",
      "[nnest.sampler] [INFO] Step [11800] loglstar [-6.6607e+00] maxlogl [-2.9076e-01] logz [-1.9335e+01] vol [7.50456e-06] ncalls [142596] scale [0.2448]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0013]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0806] validation loss [-0.0814]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.0872] validation loss [-0.0862]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.0876] validation loss [-0.0862]\n",
      "[nnest.trainer] [INFO] Epoch [150] train loss [-0.0882] validation loss [-0.0864]\n",
      "[nnest.trainer] [INFO] Epoch [200] train loss [-0.0883] validation loss [-0.0863]\n",
      "[nnest.trainer] [INFO] Epoch [212] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [162] validation loss [-0.0867]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5150] min ESS [5.1446] max ESS [8.8944] average jump distance [0.0445]\n",
      "[nnest.sampler] [INFO] Step [12000] loglstar [-6.0958e+00] maxlogl [-2.8628e-01] logz [-1.8878e+01] vol [6.14421e-06] ncalls [145627] scale [0.1484]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4600] min ESS [4.9198] max ESS [11.4682] average jump distance [0.0536]\n",
      "[nnest.sampler] [INFO] Step [12200] loglstar [-5.5490e+00] maxlogl [-2.6695e-01] logz [-1.8455e+01] vol [5.03046e-06] ncalls [148450] scale [0.4613]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5200] min ESS [8.2387] max ESS [17.4800] average jump distance [0.0600]\n",
      "[nnest.sampler] [INFO] Step [12400] loglstar [-5.1146e+00] maxlogl [-2.6695e-01] logz [-1.8074e+01] vol [4.11859e-06] ncalls [151406] scale [0.5918]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [5.4320] max ESS [11.8974] average jump distance [0.0462]\n",
      "[nnest.sampler] [INFO] Step [12600] loglstar [-4.6946e+00] maxlogl [-2.4926e-01] logz [-1.7744e+01] vol [3.37202e-06] ncalls [154374] scale [0.4960]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5900] min ESS [4.7476] max ESS [18.9678] average jump distance [0.0493]\n",
      "[nnest.sampler] [INFO] Step [12800] loglstar [-4.3746e+00] maxlogl [-1.5180e-01] logz [-1.7457e+01] vol [2.76077e-06] ncalls [157352] scale [0.2867]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0009]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0920] validation loss [-0.0938]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.0978] validation loss [-0.0972]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.0976] validation loss [-0.0958]\n",
      "[nnest.trainer] [INFO] Epoch [150] train loss [-0.0970] validation loss [-0.0969]\n",
      "[nnest.trainer] [INFO] Epoch [152] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [102] validation loss [-0.0974]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5350] min ESS [3.0280] max ESS [11.1958] average jump distance [0.0619]\n",
      "[nnest.sampler] [INFO] Step [13000] loglstar [-4.0981e+00] maxlogl [-1.5180e-01] logz [-1.7211e+01] vol [2.26033e-06] ncalls [160483] scale [0.2443]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4600] min ESS [12.1202] max ESS [21.0000] average jump distance [0.0534]\n",
      "[nnest.sampler] [INFO] Step [13200] loglstar [-3.7890e+00] maxlogl [-1.5180e-01] logz [-1.6999e+01] vol [1.85060e-06] ncalls [163352] scale [0.5820]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5550] min ESS [6.4767] max ESS [21.0000] average jump distance [0.0498]\n",
      "[nnest.sampler] [INFO] Step [13400] loglstar [-3.5059e+00] maxlogl [-3.1569e-02] logz [-1.6807e+01] vol [1.51514e-06] ncalls [166312] scale [1.1244]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4850] min ESS [5.4757] max ESS [21.0000] average jump distance [0.0539]\n",
      "[nnest.sampler] [INFO] Step [13600] loglstar [-3.1616e+00] maxlogl [-3.1569e-02] logz [-1.6630e+01] vol [1.24050e-06] ncalls [169257] scale [0.8818]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5500] min ESS [3.9666] max ESS [21.0000] average jump distance [0.0492]\n",
      "[nnest.sampler] [INFO] Step [13800] loglstar [-2.9149e+00] maxlogl [-3.1569e-02] logz [-1.6464e+01] vol [1.01563e-06] ncalls [172203] scale [0.6060]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0007]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1027] validation loss [-0.1044]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.1073] validation loss [-0.1073]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.1075] validation loss [-0.1068]\n",
      "[nnest.trainer] [INFO] Epoch [150] train loss [-0.1078] validation loss [-0.1070]\n",
      "[nnest.trainer] [INFO] Epoch [200] train loss [-0.1079] validation loss [-0.1077]\n",
      "[nnest.trainer] [INFO] Epoch [209] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [159] validation loss [-0.1081]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4950] min ESS [6.1437] max ESS [21.0000] average jump distance [0.0431]\n",
      "[nnest.sampler] [INFO] Step [14000] loglstar [-2.6888e+00] maxlogl [-3.1569e-02] logz [-1.6317e+01] vol [8.31529e-07] ncalls [175325] scale [0.2730]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] Acceptance [0.6000] min ESS [8.2898] max ESS [21.0000] average jump distance [0.0474]\n",
      "[nnest.sampler] [INFO] Step [14200] loglstar [-2.4586e+00] maxlogl [-3.1569e-02] logz [-1.6186e+01] vol [6.80798e-07] ncalls [178327] scale [1.2173]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5650] min ESS [11.2169] max ESS [21.0000] average jump distance [0.0472]\n",
      "[nnest.sampler] [INFO] Step [14400] loglstar [-2.2300e+00] maxlogl [-3.1569e-02] logz [-1.6067e+01] vol [5.57390e-07] ncalls [181175] scale [0.4172]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5550] min ESS [6.9665] max ESS [21.0000] average jump distance [0.0635]\n",
      "[nnest.sampler] [INFO] Step [14600] loglstar [-2.0404e+00] maxlogl [-3.1569e-02] logz [-1.5960e+01] vol [4.56353e-07] ncalls [184113] scale [0.1488]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4500] min ESS [18.3945] max ESS [21.0000] average jump distance [0.0663]\n",
      "[nnest.sampler] [INFO] Step [14800] loglstar [-1.8487e+00] maxlogl [-3.1569e-02] logz [-1.5864e+01] vol [3.73630e-07] ncalls [187063] scale [0.4944]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training noise [0.0006]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1134] validation loss [-0.1149]\n",
      "[nnest.trainer] [INFO] Epoch [50] train loss [-0.1176] validation loss [-0.1174]\n",
      "[nnest.trainer] [INFO] Epoch [89] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [39] validation loss [-0.1179]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4950] min ESS [4.9462] max ESS [21.0000] average jump distance [0.0411]\n",
      "[nnest.sampler] [INFO] Step [15000] loglstar [-1.6738e+00] maxlogl [-3.1569e-02] logz [-1.5777e+01] vol [3.05902e-07] ncalls [190049] scale [0.4394]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5550] min ESS [5.2510] max ESS [21.0000] average jump distance [0.0360]\n",
      "[nnest.sampler] [INFO] Step [15200] loglstar [-1.5268e+00] maxlogl [-3.1569e-02] logz [-1.5701e+01] vol [2.50452e-07] ncalls [192941] scale [0.2062]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4950] min ESS [6.0320] max ESS [21.0000] average jump distance [0.0359]\n",
      "[nnest.sampler] [INFO] Step [15400] loglstar [-1.3970e+00] maxlogl [-3.1569e-02] logz [-1.5634e+01] vol [2.05052e-07] ncalls [195949] scale [1.2431]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5050] min ESS [4.6230] max ESS [21.0000] average jump distance [0.0429]\n",
      "[nnest.sampler] [INFO] Step [15600] loglstar [-1.2571e+00] maxlogl [-3.1569e-02] logz [-1.5575e+01] vol [1.67883e-07] ncalls [198977] scale [0.8941]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5050] min ESS [13.7990] max ESS [21.0000] average jump distance [0.0394]\n",
      "[nnest.sampler] [INFO] Step [15800] loglstar [-1.1309e+00] maxlogl [-3.1569e-02] logz [-1.5522e+01] vol [1.37451e-07] ncalls [201963] scale [0.5361]\n",
      "niter: 15901\n",
      " ncall: 203487\n",
      " nsamples: 16901\n",
      " logz: -15.212 +/-  0.114\n",
      " h: 12.927\n"
     ]
    }
   ],
   "source": [
    "sampler.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.211735507625617\n"
     ]
    }
   ],
   "source": [
    "print(sampler.logz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed no burn in\n"
     ]
    }
   ],
   "source": [
    "mc = MCSamples(samples=sampler.samples, weights=sampler.weights, loglikes=-sampler.likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginalized limits: 0.68; 0.95; 0.99\n",
      "\n",
      "parameter   mean           sddev          lower1         upper1         limit1 lower2         upper2         limit2 lower3         upper3         limit3 \n",
      "param1      6.9782921E-01  4.5734261E-01  5.9107330E-01  1.1638409E+00  two   -8.2460120E-01  1.2903261E+00  two   -9.4137800E-01  1.3021322E+00  two     p_{1}\n",
      "param2      6.9846811E-01  4.0144742E-01  2.3372024E-01  1.1583869E+00  two   -5.4731162E-03  1.3961829E+00  two   -7.2732498E-02  1.4768429E+00  two     p_{2}\n",
      "param3      6.5085978E-01  5.8001572E-01 -6.8190024E-02  9.1779406E-01  two   -1.1319616E-01  1.8385974E+00  two   -1.4928935E-01  2.1172163E+00  two     p_{3}\n",
      "param4      7.5966706E-01  1.0749772E+00 -1.3684718E-01  7.7883556E-01  two   -1.7966681E-01  3.3765743E+00  two   -2.0534206E-01  4.7770319E+00  two     p_{4}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mc.getMargeStats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plots.getSubplotPlotter(width_inch=8)\n",
    "g.triangle_plot(mc, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5436.335544681886"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.getEffectiveSamples()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
