{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example notebook showing how to use the nested sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from getdist import plots, MCSamples\n",
    "import getdist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.realpath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.insert(0, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnest import NestedSampler\n",
    "from nnest.likelihoods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood + prior\n",
    "#like = Himmelblau(2)\n",
    "#transform = lambda x: 5*x\n",
    "like = Rosenbrock(10)\n",
    "transform = lambda x: 5*x\n",
    "#like = Gaussian(2, 0.9)\n",
    "#transform = lambda x: 3*x\n",
    "#like = Eggbox(2)\n",
    "#transform = lambda x: 5*np.pi*x\n",
    "#like = GaussianShell(2)\n",
    "#transform = lambda x: 5*x\n",
    "#like = GaussianMix(2)\n",
    "#transform = lambda x: 5*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory for new run logs/test/run18\n",
      "[nnest.trainer] [INFO] SingleSpeedSpline(\n",
      "  (flow): NormalizingFlow(\n",
      "    (flows): ModuleList(\n",
      "      (0): ActNorm()\n",
      "      (1): Invertible1x1Conv()\n",
      "      (2): NSF_CL(\n",
      "        (f1): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (f2): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): ActNorm()\n",
      "      (4): Invertible1x1Conv()\n",
      "      (5): NSF_CL(\n",
      "        (f1): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (f2): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): ActNorm()\n",
      "      (7): Invertible1x1Conv()\n",
      "      (8): NSF_CL(\n",
      "        (f1): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (f2): MLP(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=5, out_features=16, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "            (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (3): LeakyReLU(negative_slope=0.2)\n",
      "            (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "            (5): LeakyReLU(negative_slope=0.2)\n",
      "            (6): Linear(in_features=16, out_features=115, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[nnest.trainer] [INFO] Number of network params: [16260]\n",
      "[nnest.trainer] [INFO] Device [cpu]\n",
      "[nnest.sampler] [INFO] Num base params [10]\n",
      "[nnest.sampler] [INFO] Num derived params [0]\n",
      "[nnest.sampler] [INFO] Total params [10]\n",
      "[nnest.sampler] [INFO] Num live points [1000]\n"
     ]
    }
   ],
   "source": [
    "sampler = NestedSampler(like.x_dim, like, transform=transform, num_live_points=1000, hidden_dim=16, num_blocks=3, flow='spline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] MCMC steps [50]\n",
      "[nnest.sampler] [INFO] Initial scale [0.6325]\n",
      "[nnest.sampler] [INFO] Volume switch [-1.0000]\n",
      "[nnest.sampler] [INFO] Step [0] loglstar [-3.8737e+05] max logl [-9.0688e+03] logz [-3.8737e+05] vol [1.00000e+00] ncalls [1001] mean calls [0.0000]\n",
      "[nnest.sampler] [INFO] Step [200] loglstar [-1.7131e+05] max logl [-9.0688e+03] logz [-1.7132e+05] vol [8.18731e-01] ncalls [1216] mean calls [1.2000]\n",
      "[nnest.sampler] [INFO] Step [400] loglstar [-1.4193e+05] max logl [-9.0688e+03] logz [-1.4194e+05] vol [6.70320e-01] ncalls [1494] mean calls [1.3000]\n",
      "[nnest.sampler] [INFO] Step [600] loglstar [-1.2401e+05] max logl [-9.0688e+03] logz [-1.2402e+05] vol [5.48812e-01] ncalls [1819] mean calls [1.5500]\n",
      "[nnest.sampler] [INFO] Step [800] loglstar [-1.0887e+05] max logl [-9.0688e+03] logz [-1.0888e+05] vol [4.49329e-01] ncalls [2205] mean calls [2.1000]\n",
      "[nnest.sampler] [INFO] Step [1000] loglstar [-9.7810e+04] max logl [-9.0688e+03] logz [-9.7818e+04] vol [3.67879e-01] ncalls [2707] mean calls [2.6500]\n",
      "[nnest.sampler] [INFO] Step [1200] loglstar [-8.8026e+04] max logl [-9.0688e+03] logz [-8.8034e+04] vol [3.01194e-01] ncalls [3298] mean calls [2.6000]\n",
      "[nnest.sampler] [INFO] Step [1400] loglstar [-7.8807e+04] max logl [-9.0688e+03] logz [-7.8815e+04] vol [2.46597e-01] ncalls [3982] mean calls [5.2500]\n",
      "[nnest.sampler] [INFO] Step [1600] loglstar [-7.2368e+04] max logl [-7.3690e+03] logz [-7.2377e+04] vol [2.01897e-01] ncalls [4942] mean calls [5.2000]\n",
      "[nnest.sampler] [INFO] Step [1800] loglstar [-6.6996e+04] max logl [-4.5405e+03] logz [-6.7004e+04] vol [1.65299e-01] ncalls [6006] mean calls [5.7000]\n",
      "[nnest.sampler] [INFO] Step [2000] loglstar [-6.1311e+04] max logl [-3.9193e+03] logz [-6.1320e+04] vol [1.35335e-01] ncalls [7237] mean calls [6.0500]\n",
      "[nnest.sampler] [INFO] Step [2200] loglstar [-5.6566e+04] max logl [-3.9193e+03] logz [-5.6575e+04] vol [1.10803e-01] ncalls [8853] mean calls [8.2500]\n",
      "[nnest.sampler] [INFO] Step [2400] loglstar [-5.2443e+04] max logl [-3.9193e+03] logz [-5.2451e+04] vol [9.07180e-02] ncalls [11059] mean calls [10.5500]\n",
      "[nnest.sampler] [INFO] Step [2600] loglstar [-4.7868e+04] max logl [-3.9193e+03] logz [-4.7877e+04] vol [7.42736e-02] ncalls [13151] mean calls [10.0500]\n",
      "[nnest.sampler] [INFO] Step [2800] loglstar [-4.3685e+04] max logl [-3.9193e+03] logz [-4.3695e+04] vol [6.08101e-02] ncalls [15818] mean calls [16.4000]\n",
      "[nnest.sampler] [INFO] Step [3000] loglstar [-3.9508e+04] max logl [-3.4601e+03] logz [-3.9517e+04] vol [4.97871e-02] ncalls [19493] mean calls [17.2000]\n",
      "[nnest.sampler] [INFO] Step [3200] loglstar [-3.6059e+04] max logl [-3.4601e+03] logz [-3.6069e+04] vol [4.07622e-02] ncalls [23758] mean calls [24.6000]\n",
      "[nnest.sampler] [INFO] Step [3400] loglstar [-3.2953e+04] max logl [-1.2278e+03] logz [-3.2963e+04] vol [3.33733e-02] ncalls [29085] mean calls [35.0000]\n",
      "[nnest.sampler] [INFO] Rejection prior no longer efficient, switching sampling method\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0680]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0554] validation loss [0.0517]\n",
      "[nnest.trainer] [INFO] Epoch [80] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [30] validation loss [0.0467] train time (s) [25.4756]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5620] min ESS [1.7875] max ESS [4.9781] average jump [0.1348]\n",
      "[nnest.sampler] [INFO] Step [3600] loglstar [-3.0375e+04] maxlogl [-1.2278e+03] logz [-3.0386e+04] vol [2.73237e-02] ncalls [36370] scale [0.1999]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4860] min ESS [2.2663] max ESS [5.7636] average jump [0.1676]\n",
      "[nnest.sampler] [INFO] Step [3800] loglstar [-2.7727e+04] maxlogl [-1.2278e+03] logz [-2.7737e+04] vol [2.23708e-02] ncalls [43847] scale [0.2262]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0650]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0406] validation loss [0.0397]\n",
      "[nnest.trainer] [INFO] Epoch [51] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [1] validation loss [0.0397] train time (s) [15.7495]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5520] min ESS [1.7530] max ESS [4.0650] average jump [0.1223]\n",
      "[nnest.sampler] [INFO] Step [4000] loglstar [-2.5182e+04] maxlogl [-1.2278e+03] logz [-2.5193e+04] vol [1.83156e-02] ncalls [51632] scale [0.2660]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5060] min ESS [2.0529] max ESS [4.9656] average jump [0.1277]\n",
      "[nnest.sampler] [INFO] Step [4200] loglstar [-2.3441e+04] maxlogl [-8.2858e+02] logz [-2.3452e+04] vol [1.49956e-02] ncalls [59125] scale [0.1550]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5480] min ESS [1.9422] max ESS [5.1774] average jump [0.1251]\n",
      "[nnest.sampler] [INFO] Step [4400] loglstar [-2.1490e+04] maxlogl [-8.2858e+02] logz [-2.1501e+04] vol [1.22773e-02] ncalls [66567] scale [0.0896]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5100] min ESS [1.3385] max ESS [3.9723] average jump [0.1272]\n",
      "[nnest.sampler] [INFO] Step [4600] loglstar [-1.9809e+04] maxlogl [-8.2858e+02] logz [-1.9820e+04] vol [1.00518e-02] ncalls [74185] scale [0.1412]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4940] min ESS [2.3139] max ESS [7.7335] average jump [0.1563]\n",
      "[nnest.sampler] [INFO] Step [4800] loglstar [-1.8309e+04] maxlogl [-8.2858e+02] logz [-1.8320e+04] vol [8.22975e-03] ncalls [81746] scale [0.3770]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0590]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0341] validation loss [0.0338]\n",
      "[nnest.trainer] [INFO] Epoch [59] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [9] validation loss [0.0328] train time (s) [17.4317]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5220] min ESS [2.7428] max ESS [7.5864] average jump [0.1420]\n",
      "[nnest.sampler] [INFO] Step [5000] loglstar [-1.6785e+04] maxlogl [-8.2858e+02] logz [-1.6797e+04] vol [6.73795e-03] ncalls [89258] scale [0.1703]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5140] min ESS [2.4555] max ESS [6.5742] average jump [0.1418]\n",
      "[nnest.sampler] [INFO] Step [5200] loglstar [-1.5443e+04] maxlogl [-8.2858e+02] logz [-1.5455e+04] vol [5.51656e-03] ncalls [96994] scale [0.3204]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5400] min ESS [3.4124] max ESS [7.4528] average jump [0.1584]\n",
      "[nnest.sampler] [INFO] Step [5400] loglstar [-1.4238e+04] maxlogl [-8.2858e+02] logz [-1.4250e+04] vol [4.51658e-03] ncalls [104598] scale [0.1290]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5440] min ESS [2.5418] max ESS [11.5941] average jump [0.1285]\n",
      "[nnest.sampler] [INFO] Step [5600] loglstar [-1.3206e+04] maxlogl [-8.2858e+02] logz [-1.3218e+04] vol [3.69786e-03] ncalls [112263] scale [0.1524]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5140] min ESS [2.4656] max ESS [6.5028] average jump [0.1256]\n",
      "[nnest.sampler] [INFO] Step [5800] loglstar [-1.2150e+04] maxlogl [-7.0298e+02] logz [-1.2162e+04] vol [3.02755e-03] ncalls [119877] scale [0.1781]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0530]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0232] validation loss [0.0187]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [0.0115] validation loss [0.0185]\n",
      "[nnest.trainer] [INFO] Epoch [102] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [52] validation loss [0.0167] train time (s) [30.7706]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5860] min ESS [1.9730] max ESS [16.4260] average jump [0.1499]\n",
      "[nnest.sampler] [INFO] Step [6000] loglstar [-1.1112e+04] maxlogl [-7.0298e+02] logz [-1.1125e+04] vol [2.47875e-03] ncalls [127781] scale [0.4288]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4580] min ESS [2.0693] max ESS [8.8393] average jump [0.1469]\n",
      "[nnest.sampler] [INFO] Step [6200] loglstar [-1.0214e+04] maxlogl [-7.0298e+02] logz [-1.0227e+04] vol [2.02943e-03] ncalls [134867] scale [0.3648]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5460] min ESS [2.0296] max ESS [11.4381] average jump [0.1386]\n",
      "[nnest.sampler] [INFO] Step [6400] loglstar [-9.3125e+03] maxlogl [-7.0298e+02] logz [-9.3251e+03] vol [1.66156e-03] ncalls [142447] scale [0.2177]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5180] min ESS [1.9149] max ESS [12.7427] average jump [0.1369]\n",
      "[nnest.sampler] [INFO] Step [6600] loglstar [-8.5376e+03] maxlogl [-7.0298e+02] logz [-8.5511e+03] vol [1.36037e-03] ncalls [149656] scale [0.3008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] Acceptance [0.5420] min ESS [3.8995] max ESS [11.9810] average jump [0.1668]\n",
      "[nnest.sampler] [INFO] Step [6800] loglstar [-7.9392e+03] maxlogl [-7.0298e+02] logz [-7.9529e+03] vol [1.11378e-03] ncalls [156937] scale [0.4263]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0482]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0110] validation loss [0.0097]\n",
      "[nnest.trainer] [INFO] Epoch [56] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [6] validation loss [0.0086] train time (s) [18.2133]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5320] min ESS [2.2472] max ESS [7.5194] average jump [0.1233]\n",
      "[nnest.sampler] [INFO] Step [7000] loglstar [-7.3770e+03] maxlogl [-7.0298e+02] logz [-7.3909e+03] vol [9.11882e-04] ncalls [164202] scale [0.1760]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5180] min ESS [1.5459] max ESS [11.7539] average jump [0.1173]\n",
      "[nnest.sampler] [INFO] Step [7200] loglstar [-6.7762e+03] maxlogl [-7.0034e+02] logz [-6.7902e+03] vol [7.46586e-04] ncalls [171610] scale [0.4430]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4820] min ESS [1.9742] max ESS [12.6730] average jump [0.1081]\n",
      "[nnest.sampler] [INFO] Step [7400] loglstar [-6.2701e+03] maxlogl [-7.0034e+02] logz [-6.2843e+03] vol [6.11253e-04] ncalls [178928] scale [0.3053]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5780] min ESS [3.0323] max ESS [9.7472] average jump [0.1040]\n",
      "[nnest.sampler] [INFO] Step [7600] loglstar [-5.8238e+03] maxlogl [-7.0034e+02] logz [-5.8376e+03] vol [5.00451e-04] ncalls [186396] scale [0.1979]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5020] min ESS [2.4201] max ESS [12.2269] average jump [0.1351]\n",
      "[nnest.sampler] [INFO] Step [7800] loglstar [-5.3425e+03] maxlogl [-7.0034e+02] logz [-5.3568e+03] vol [4.09735e-04] ncalls [193943] scale [0.3394]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0436]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [0.0024] validation loss [0.0007]\n",
      "[nnest.trainer] [INFO] Epoch [69] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [19] validation loss [-0.0012] train time (s) [21.0555]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5220] min ESS [2.6947] max ESS [7.1451] average jump [0.1085]\n",
      "[nnest.sampler] [INFO] Step [8000] loglstar [-4.9366e+03] maxlogl [-7.0034e+02] logz [-4.9515e+03] vol [3.35463e-04] ncalls [201472] scale [0.2015]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5980] min ESS [3.5490] max ESS [8.5375] average jump [0.1217]\n",
      "[nnest.sampler] [INFO] Step [8200] loglstar [-4.5780e+03] maxlogl [-7.0034e+02] logz [-4.5929e+03] vol [2.74654e-04] ncalls [208938] scale [0.2575]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5560] min ESS [3.1880] max ESS [9.7646] average jump [0.1259]\n",
      "[nnest.sampler] [INFO] Step [8400] loglstar [-4.2588e+03] maxlogl [-6.3920e+02] logz [-4.2739e+03] vol [2.24867e-04] ncalls [216647] scale [0.3118]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5740] min ESS [3.3556] max ESS [7.6768] average jump [0.1005]\n",
      "[nnest.sampler] [INFO] Step [8600] loglstar [-3.9598e+03] maxlogl [-5.9787e+02] logz [-3.9744e+03] vol [1.84106e-04] ncalls [224006] scale [0.3505]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5260] min ESS [3.1269] max ESS [9.7823] average jump [0.1132]\n",
      "[nnest.sampler] [INFO] Step [8800] loglstar [-3.6809e+03] maxlogl [-4.9159e+02] logz [-3.6955e+03] vol [1.50733e-04] ncalls [231396] scale [0.1471]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0396]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0083] validation loss [-0.0116]\n",
      "[nnest.trainer] [INFO] Epoch [63] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [13] validation loss [-0.0133] train time (s) [21.9458]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5380] min ESS [2.0551] max ESS [13.4639] average jump [0.1080]\n",
      "[nnest.sampler] [INFO] Step [9000] loglstar [-3.4301e+03] maxlogl [-4.8182e+02] logz [-3.4456e+03] vol [1.23410e-04] ncalls [238747] scale [0.1694]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5340] min ESS [4.2957] max ESS [13.8384] average jump [0.1371]\n",
      "[nnest.sampler] [INFO] Step [9200] loglstar [-3.1834e+03] maxlogl [-3.3029e+02] logz [-3.1984e+03] vol [1.01039e-04] ncalls [246201] scale [0.3489]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4580] min ESS [3.0850] max ESS [9.9961] average jump [0.1115]\n",
      "[nnest.sampler] [INFO] Step [9400] loglstar [-2.9594e+03] maxlogl [-3.3029e+02] logz [-2.9751e+03] vol [8.27241e-05] ncalls [253483] scale [0.1906]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5300] min ESS [3.9595] max ESS [9.5349] average jump [0.1099]\n",
      "[nnest.sampler] [INFO] Step [9600] loglstar [-2.7615e+03] maxlogl [-3.3029e+02] logz [-2.7771e+03] vol [6.77287e-05] ncalls [260894] scale [0.2761]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6020] min ESS [2.0710] max ESS [12.5488] average jump [0.0907]\n",
      "[nnest.sampler] [INFO] Step [9800] loglstar [-2.5765e+03] maxlogl [-3.3029e+02] logz [-2.5929e+03] vol [5.54516e-05] ncalls [268373] scale [0.2330]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0360]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0180] validation loss [-0.0195]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.0282] validation loss [-0.0198]\n",
      "[nnest.trainer] [INFO] Epoch [119] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [69] validation loss [-0.0214] train time (s) [38.3298]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5720] min ESS [2.4389] max ESS [8.1328] average jump [0.0968]\n",
      "[nnest.sampler] [INFO] Step [10000] loglstar [-2.4139e+03] maxlogl [-3.3029e+02] logz [-2.4308e+03] vol [4.53999e-05] ncalls [275819] scale [0.1503]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4720] min ESS [6.7951] max ESS [16.6572] average jump [0.1250]\n",
      "[nnest.sampler] [INFO] Step [10200] loglstar [-2.2537e+03] maxlogl [-7.1781e+01] logz [-2.2704e+03] vol [3.71703e-05] ncalls [282910] scale [0.2586]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5460] min ESS [4.0275] max ESS [10.2492] average jump [0.0945]\n",
      "[nnest.sampler] [INFO] Step [10400] loglstar [-2.0939e+03] maxlogl [-7.1781e+01] logz [-2.1109e+03] vol [3.04325e-05] ncalls [289862] scale [0.2988]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5300] min ESS [3.5187] max ESS [16.8854] average jump [0.0972]\n",
      "[nnest.sampler] [INFO] Step [10600] loglstar [-1.9572e+03] maxlogl [-7.1781e+01] logz [-1.9740e+03] vol [2.49160e-05] ncalls [296752] scale [0.2277]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5620] min ESS [5.0789] max ESS [12.5452] average jump [0.1048]\n",
      "[nnest.sampler] [INFO] Step [10800] loglstar [-1.8316e+03] maxlogl [-7.1781e+01] logz [-1.8480e+03] vol [2.03995e-05] ncalls [304188] scale [0.2767]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0326]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0277] validation loss [-0.0314]\n",
      "[nnest.trainer] [INFO] Epoch [60] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [10] validation loss [-0.0326] train time (s) [19.2198]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5600] min ESS [3.8926] max ESS [19.3943] average jump [0.0906]\n",
      "[nnest.sampler] [INFO] Step [11000] loglstar [-1.6966e+03] maxlogl [-7.1781e+01] logz [-1.7138e+03] vol [1.67017e-05] ncalls [311216] scale [0.1025]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5620] min ESS [4.0494] max ESS [14.6842] average jump [0.0937]\n",
      "[nnest.sampler] [INFO] Step [11200] loglstar [-1.5841e+03] maxlogl [-7.1781e+01] logz [-1.6009e+03] vol [1.36742e-05] ncalls [318459] scale [0.2328]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5180] min ESS [3.7472] max ESS [13.5201] average jump [0.0870]\n",
      "[nnest.sampler] [INFO] Step [11400] loglstar [-1.4687e+03] maxlogl [-7.1781e+01] logz [-1.4862e+03] vol [1.11955e-05] ncalls [325722] scale [0.6271]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5200] min ESS [2.6676] max ESS [12.6157] average jump [0.0719]\n",
      "[nnest.sampler] [INFO] Step [11600] loglstar [-1.3760e+03] maxlogl [-7.1781e+01] logz [-1.3934e+03] vol [9.16609e-06] ncalls [332995] scale [0.1856]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5560] min ESS [2.4709] max ESS [12.9654] average jump [0.0728]\n",
      "[nnest.sampler] [INFO] Step [11800] loglstar [-1.2811e+03] maxlogl [-7.1781e+01] logz [-1.2993e+03] vol [7.50456e-06] ncalls [340349] scale [0.1759]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.trainer] [INFO] Training jitter [0.0298]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0371] validation loss [-0.0415]\n",
      "[nnest.trainer] [INFO] Epoch [65] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [15] validation loss [-0.0417] train time (s) [23.8779]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5060] min ESS [4.1942] max ESS [17.3517] average jump [0.0964]\n",
      "[nnest.sampler] [INFO] Step [12000] loglstar [-1.2035e+03] maxlogl [-7.1781e+01] logz [-1.2213e+03] vol [6.14421e-06] ncalls [347480] scale [0.3107]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5180] min ESS [4.5348] max ESS [9.3312] average jump [0.0713]\n",
      "[nnest.sampler] [INFO] Step [12200] loglstar [-1.1290e+03] maxlogl [-7.1781e+01] logz [-1.1470e+03] vol [5.03046e-06] ncalls [354983] scale [0.4795]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5100] min ESS [3.3530] max ESS [9.8057] average jump [0.0812]\n",
      "[nnest.sampler] [INFO] Step [12400] loglstar [-1.0549e+03] maxlogl [-7.1781e+01] logz [-1.0736e+03] vol [4.11859e-06] ncalls [362288] scale [0.2028]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5040] min ESS [4.8968] max ESS [11.6454] average jump [0.0825]\n",
      "[nnest.sampler] [INFO] Step [12600] loglstar [-9.9566e+02] maxlogl [-7.1781e+01] logz [-1.0134e+03] vol [3.37202e-06] ncalls [369616] scale [0.3232]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5440] min ESS [3.0746] max ESS [13.9821] average jump [0.0760]\n",
      "[nnest.sampler] [INFO] Step [12800] loglstar [-9.3153e+02] maxlogl [-7.1781e+01] logz [-9.4992e+02] vol [2.76077e-06] ncalls [377342] scale [0.1941]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0270]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0474] validation loss [-0.0498]\n",
      "[nnest.trainer] [INFO] Epoch [70] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [20] validation loss [-0.0510] train time (s) [23.2654]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5340] min ESS [4.8232] max ESS [15.7081] average jump [0.0834]\n",
      "[nnest.sampler] [INFO] Step [13000] loglstar [-8.7675e+02] maxlogl [-7.1781e+01] logz [-8.9535e+02] vol [2.26033e-06] ncalls [384644] scale [0.1402]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5680] min ESS [4.1436] max ESS [17.8237] average jump [0.0671]\n",
      "[nnest.sampler] [INFO] Step [13200] loglstar [-8.2593e+02] maxlogl [-7.1781e+01] logz [-8.4449e+02] vol [1.85060e-06] ncalls [391873] scale [0.1429]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5500] min ESS [5.1458] max ESS [23.4532] average jump [0.0875]\n",
      "[nnest.sampler] [INFO] Step [13400] loglstar [-7.8306e+02] maxlogl [-7.1781e+01] logz [-8.0156e+02] vol [1.51514e-06] ncalls [399220] scale [0.1754]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4740] min ESS [3.3885] max ESS [14.8923] average jump [0.0701]\n",
      "[nnest.sampler] [INFO] Step [13600] loglstar [-7.3432e+02] maxlogl [-7.1781e+01] logz [-7.5308e+02] vol [1.24050e-06] ncalls [406668] scale [0.2466]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5880] min ESS [4.4437] max ESS [22.6361] average jump [0.0741]\n",
      "[nnest.sampler] [INFO] Step [13800] loglstar [-6.8743e+02] maxlogl [-7.1781e+01] logz [-7.0622e+02] vol [1.01563e-06] ncalls [414239] scale [0.1315]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0243]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0573] validation loss [-0.0600]\n",
      "[nnest.trainer] [INFO] Epoch [99] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [49] validation loss [-0.0614] train time (s) [32.4397]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5640] min ESS [5.7857] max ESS [22.1263] average jump [0.0790]\n",
      "[nnest.sampler] [INFO] Step [14000] loglstar [-6.4747e+02] maxlogl [-7.1781e+01] logz [-6.6644e+02] vol [8.31529e-07] ncalls [421733] scale [0.1272]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [4.4878] max ESS [12.9845] average jump [0.0610]\n",
      "[nnest.sampler] [INFO] Step [14200] loglstar [-6.0554e+02] maxlogl [-7.1781e+01] logz [-6.2452e+02] vol [6.80798e-07] ncalls [429092] scale [0.2131]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5600] min ESS [6.5229] max ESS [15.5037] average jump [0.0677]\n",
      "[nnest.sampler] [INFO] Step [14400] loglstar [-5.7447e+02] maxlogl [-7.1781e+01] logz [-5.9365e+02] vol [5.57390e-07] ncalls [436344] scale [0.1633]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5140] min ESS [2.4698] max ESS [33.3670] average jump [0.0687]\n",
      "[nnest.sampler] [INFO] Step [14600] loglstar [-5.4176e+02] maxlogl [-7.1781e+01] logz [-5.6107e+02] vol [4.56353e-07] ncalls [443623] scale [0.1702]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5760] min ESS [5.4236] max ESS [11.3647] average jump [0.0645]\n",
      "[nnest.sampler] [INFO] Step [14800] loglstar [-5.1423e+02] maxlogl [-7.1781e+01] logz [-5.3384e+02] vol [3.73630e-07] ncalls [451031] scale [0.3558]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0224]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0670] validation loss [-0.0716]\n",
      "[nnest.trainer] [INFO] Epoch [57] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [7] validation loss [-0.0736] train time (s) [18.0706]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5240] min ESS [2.9257] max ESS [23.6838] average jump [0.0589]\n",
      "[nnest.sampler] [INFO] Step [15000] loglstar [-4.8789e+02] maxlogl [-7.1781e+01] logz [-5.0761e+02] vol [3.05902e-07] ncalls [458317] scale [0.1525]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4660] min ESS [4.6886] max ESS [32.7687] average jump [0.0739]\n",
      "[nnest.sampler] [INFO] Step [15200] loglstar [-4.6064e+02] maxlogl [-7.1781e+01] logz [-4.8052e+02] vol [2.50452e-07] ncalls [465888] scale [0.2541]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4460] min ESS [5.1238] max ESS [35.4556] average jump [0.0692]\n",
      "[nnest.sampler] [INFO] Step [15400] loglstar [-4.3405e+02] maxlogl [-7.1781e+01] logz [-4.5396e+02] vol [2.05052e-07] ncalls [473213] scale [0.3042]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5960] min ESS [4.0702] max ESS [15.7365] average jump [0.0498]\n",
      "[nnest.sampler] [INFO] Step [15600] loglstar [-4.0860e+02] maxlogl [-7.1781e+01] logz [-4.2931e+02] vol [1.67883e-07] ncalls [480622] scale [0.1558]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5360] min ESS [3.5417] max ESS [46.3625] average jump [0.0592]\n",
      "[nnest.sampler] [INFO] Step [15800] loglstar [-3.8687e+02] maxlogl [-7.1781e+01] logz [-4.0736e+02] vol [1.37451e-07] ncalls [488122] scale [0.3258]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0204]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0762] validation loss [-0.0806]\n",
      "[nnest.trainer] [INFO] Epoch [52] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [2] validation loss [-0.0812] train time (s) [16.5375]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5080] min ESS [8.4609] max ESS [42.4701] average jump [0.0680]\n",
      "[nnest.sampler] [INFO] Step [16000] loglstar [-3.6608e+02] maxlogl [-7.1781e+01] logz [-3.8670e+02] vol [1.12535e-07] ncalls [495647] scale [0.2821]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5240] min ESS [1.6983] max ESS [16.1787] average jump [0.0470]\n",
      "[nnest.sampler] [INFO] Step [16200] loglstar [-3.4737e+02] maxlogl [-7.1781e+01] logz [-3.6781e+02] vol [9.21360e-08] ncalls [503210] scale [0.1487]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5220] min ESS [3.6739] max ESS [14.3053] average jump [0.0519]\n",
      "[nnest.sampler] [INFO] Step [16400] loglstar [-3.3000e+02] maxlogl [-7.1781e+01] logz [-3.5046e+02] vol [7.54346e-08] ncalls [511241] scale [0.2151]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5580] min ESS [5.1738] max ESS [42.4948] average jump [0.0462]\n",
      "[nnest.sampler] [INFO] Step [16600] loglstar [-3.1247e+02] maxlogl [-7.0990e+01] logz [-3.3320e+02] vol [6.17606e-08] ncalls [518919] scale [0.2665]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6020] min ESS [6.5546] max ESS [22.5048] average jump [0.0566]\n",
      "[nnest.sampler] [INFO] Step [16800] loglstar [-2.9720e+02] maxlogl [-7.0990e+01] logz [-3.1847e+02] vol [5.05653e-08] ncalls [526525] scale [0.2306]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0184]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0849] validation loss [-0.0886]\n",
      "[nnest.trainer] [INFO] Epoch [66] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [16] validation loss [-0.0901] train time (s) [21.0654]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5000] min ESS [2.8818] max ESS [42.2562] average jump [0.0599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] Step [17000] loglstar [-2.8367e+02] maxlogl [-5.0739e+01] logz [-3.0483e+02] vol [4.13994e-08] ncalls [534289] scale [0.2090]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6160] min ESS [2.1051] max ESS [17.5287] average jump [0.0474]\n",
      "[nnest.sampler] [INFO] Step [17200] loglstar [-2.7044e+02] maxlogl [-5.0739e+01] logz [-2.9160e+02] vol [3.38949e-08] ncalls [541835] scale [0.4320]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4820] min ESS [10.3245] max ESS [38.9810] average jump [0.0574]\n",
      "[nnest.sampler] [INFO] Step [17400] loglstar [-2.5847e+02] maxlogl [-5.0739e+01] logz [-2.7981e+02] vol [2.77508e-08] ncalls [549355] scale [0.2452]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5640] min ESS [14.7832] max ESS [33.5112] average jump [0.0511]\n",
      "[nnest.sampler] [INFO] Step [17600] loglstar [-2.4718e+02] maxlogl [-3.4552e+01] logz [-2.6863e+02] vol [2.27205e-08] ncalls [556693] scale [0.1924]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4380] min ESS [10.1526] max ESS [42.2420] average jump [0.0527]\n",
      "[nnest.sampler] [INFO] Step [17800] loglstar [-2.3615e+02] maxlogl [-2.7819e+01] logz [-2.5798e+02] vol [1.86019e-08] ncalls [564069] scale [0.3577]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0166]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.0960] validation loss [-0.0991]\n",
      "[nnest.trainer] [INFO] Epoch [51] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [1] validation loss [-0.0991] train time (s) [16.7196]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5220] min ESS [6.9895] max ESS [29.2605] average jump [0.0455]\n",
      "[nnest.sampler] [INFO] Step [18000] loglstar [-2.2350e+02] maxlogl [-2.7819e+01] logz [-2.4545e+02] vol [1.52300e-08] ncalls [571532] scale [0.3140]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5060] min ESS [6.8514] max ESS [51.0000] average jump [0.0522]\n",
      "[nnest.sampler] [INFO] Step [18200] loglstar [-2.1352e+02] maxlogl [-2.7819e+01] logz [-2.3546e+02] vol [1.24693e-08] ncalls [579166] scale [0.1504]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5740] min ESS [3.2059] max ESS [22.0997] average jump [0.0437]\n",
      "[nnest.sampler] [INFO] Step [18400] loglstar [-2.0400e+02] maxlogl [-2.7819e+01] logz [-2.2634e+02] vol [1.02090e-08] ncalls [586738] scale [0.1777]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5540] min ESS [7.3384] max ESS [46.3642] average jump [0.0400]\n",
      "[nnest.sampler] [INFO] Step [18600] loglstar [-1.9512e+02] maxlogl [-2.7819e+01] logz [-2.1757e+02] vol [8.35839e-09] ncalls [594501] scale [0.2325]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5500] min ESS [6.8912] max ESS [42.4657] average jump [0.0504]\n",
      "[nnest.sampler] [INFO] Step [18800] loglstar [-1.8587e+02] maxlogl [-2.7819e+01] logz [-2.0836e+02] vol [6.84327e-09] ncalls [601990] scale [0.5149]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0152]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1044] validation loss [-0.1083]\n",
      "[nnest.trainer] [INFO] Epoch [55] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [5] validation loss [-0.1098] train time (s) [16.8805]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4900] min ESS [9.8775] max ESS [51.0000] average jump [0.0468]\n",
      "[nnest.sampler] [INFO] Step [19000] loglstar [-1.7646e+02] maxlogl [-2.7819e+01] logz [-1.9908e+02] vol [5.60280e-09] ncalls [609742] scale [0.1329]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5400] min ESS [4.4406] max ESS [51.0000] average jump [0.0453]\n",
      "[nnest.sampler] [INFO] Step [19200] loglstar [-1.6791e+02] maxlogl [-2.7819e+01] logz [-1.9113e+02] vol [4.58718e-09] ncalls [617667] scale [0.3315]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5260] min ESS [7.2833] max ESS [20.0779] average jump [0.0432]\n",
      "[nnest.sampler] [INFO] Step [19400] loglstar [-1.6063e+02] maxlogl [-2.7819e+01] logz [-1.8359e+02] vol [3.75567e-09] ncalls [625326] scale [0.1160]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5220] min ESS [1.9956] max ESS [31.6500] average jump [0.0367]\n",
      "[nnest.sampler] [INFO] Step [19600] loglstar [-1.5363e+02] maxlogl [-2.7819e+01] logz [-1.7688e+02] vol [3.07488e-09] ncalls [632864] scale [0.1628]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5560] min ESS [1.7886] max ESS [51.0000] average jump [0.0349]\n",
      "[nnest.sampler] [INFO] Step [19800] loglstar [-1.4698e+02] maxlogl [-2.7819e+01] logz [-1.7046e+02] vol [2.51750e-09] ncalls [640533] scale [0.2914]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0136]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1140] validation loss [-0.1169]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.1245] validation loss [-0.1164]\n",
      "[nnest.trainer] [INFO] Epoch [100] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [50] validation loss [-0.1192] train time (s) [33.0630]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [6.3520] max ESS [16.6847] average jump [0.0370]\n",
      "[nnest.sampler] [INFO] Step [20000] loglstar [-1.3999e+02] maxlogl [-2.7819e+01] logz [-1.6354e+02] vol [2.06115e-09] ncalls [648311] scale [0.1201]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5160] min ESS [8.7142] max ESS [51.0000] average jump [0.0407]\n",
      "[nnest.sampler] [INFO] Step [20200] loglstar [-1.3389e+02] maxlogl [-2.7819e+01] logz [-1.5736e+02] vol [1.68753e-09] ncalls [655753] scale [0.3637]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5680] min ESS [3.3688] max ESS [13.9155] average jump [0.0265]\n",
      "[nnest.sampler] [INFO] Step [20400] loglstar [-1.2798e+02] maxlogl [-2.7819e+01] logz [-1.5170e+02] vol [1.38163e-09] ncalls [663339] scale [0.1128]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4460] min ESS [9.9669] max ESS [51.0000] average jump [0.0374]\n",
      "[nnest.sampler] [INFO] Step [20600] loglstar [-1.2317e+02] maxlogl [-2.7819e+01] logz [-1.4698e+02] vol [1.13119e-09] ncalls [670810] scale [0.4453]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6000] min ESS [5.6590] max ESS [51.0000] average jump [0.0345]\n",
      "[nnest.sampler] [INFO] Step [20800] loglstar [-1.1752e+02] maxlogl [-2.7819e+01] logz [-1.4164e+02] vol [9.26136e-10] ncalls [678461] scale [0.1095]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0123]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1266] validation loss [-0.1308]\n",
      "[nnest.trainer] [INFO] Epoch [52] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [2] validation loss [-0.1309] train time (s) [17.2747]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6900] min ESS [8.8139] max ESS [51.0000] average jump [0.0259]\n",
      "[nnest.sampler] [INFO] Step [21000] loglstar [-1.1271e+02] maxlogl [-2.7819e+01] logz [-1.3687e+02] vol [7.58256e-10] ncalls [686003] scale [0.2183]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4900] min ESS [8.7648] max ESS [46.3518] average jump [0.0364]\n",
      "[nnest.sampler] [INFO] Step [21200] loglstar [-1.0829e+02] maxlogl [-2.7819e+01] logz [-1.3258e+02] vol [6.20808e-10] ncalls [693572] scale [0.2816]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4660] min ESS [7.0497] max ESS [51.0000] average jump [0.0345]\n",
      "[nnest.sampler] [INFO] Step [21400] loglstar [-1.0391e+02] maxlogl [-2.7819e+01] logz [-1.2824e+02] vol [5.08274e-10] ncalls [701123] scale [0.3155]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5180] min ESS [7.7980] max ESS [51.0000] average jump [0.0376]\n",
      "[nnest.sampler] [INFO] Step [21600] loglstar [-9.9299e+01] maxlogl [-2.7819e+01] logz [-1.2385e+02] vol [4.16140e-10] ncalls [708575] scale [0.1792]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4880] min ESS [9.4918] max ESS [51.0000] average jump [0.0280]\n",
      "[nnest.sampler] [INFO] Step [21800] loglstar [-9.5460e+01] maxlogl [-2.7819e+01] logz [-1.2016e+02] vol [3.40706e-10] ncalls [716269] scale [0.1510]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0110]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1352] validation loss [-0.1370]\n",
      "[nnest.trainer] [INFO] Epoch [54] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [4] validation loss [-0.1378] train time (s) [17.1197]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5500] min ESS [9.7461] max ESS [51.0000] average jump [0.0293]\n",
      "[nnest.sampler] [INFO] Step [22000] loglstar [-9.1657e+01] maxlogl [-2.7819e+01] logz [-1.1652e+02] vol [2.78947e-10] ncalls [724345] scale [0.4883]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5440] min ESS [8.6794] max ESS [51.0000] average jump [0.0306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] Step [22200] loglstar [-8.7922e+01] maxlogl [-2.7819e+01] logz [-1.1291e+02] vol [2.28382e-10] ncalls [732074] scale [0.3521]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5560] min ESS [7.7479] max ESS [51.0000] average jump [0.0327]\n",
      "[nnest.sampler] [INFO] Step [22400] loglstar [-8.4869e+01] maxlogl [-2.7819e+01] logz [-1.0992e+02] vol [1.86984e-10] ncalls [739740] scale [0.2625]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5460] min ESS [13.4291] max ESS [51.0000] average jump [0.0336]\n",
      "[nnest.sampler] [INFO] Step [22600] loglstar [-8.1427e+01] maxlogl [-2.7819e+01] logz [-1.0668e+02] vol [1.53089e-10] ncalls [747437] scale [0.3285]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5860] min ESS [9.2360] max ESS [51.0000] average jump [0.0272]\n",
      "[nnest.sampler] [INFO] Step [22800] loglstar [-7.8393e+01] maxlogl [-2.7819e+01] logz [-1.0379e+02] vol [1.25339e-10] ncalls [755275] scale [0.2351]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0102]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1440] validation loss [-0.1494]\n",
      "[nnest.trainer] [INFO] Epoch [64] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [14] validation loss [-0.1498] train time (s) [20.1323]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5680] min ESS [10.5508] max ESS [51.0000] average jump [0.0302]\n",
      "[nnest.sampler] [INFO] Step [23000] loglstar [-7.5540e+01] maxlogl [-2.7025e+01] logz [-1.0108e+02] vol [1.02619e-10] ncalls [763042] scale [0.2286]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5500] min ESS [10.9430] max ESS [51.0000] average jump [0.0214]\n",
      "[nnest.sampler] [INFO] Step [23200] loglstar [-7.2532e+01] maxlogl [-2.7025e+01] logz [-9.8351e+01] vol [8.40172e-11] ncalls [770634] scale [0.2573]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5740] min ESS [5.8911] max ESS [51.0000] average jump [0.0312]\n",
      "[nnest.sampler] [INFO] Step [23400] loglstar [-6.9905e+01] maxlogl [-2.2621e+01] logz [-9.5788e+01] vol [6.87874e-11] ncalls [778334] scale [0.3641]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5440] min ESS [10.4120] max ESS [51.0000] average jump [0.0264]\n",
      "[nnest.sampler] [INFO] Step [23600] loglstar [-6.7216e+01] maxlogl [-2.2593e+01] logz [-9.3260e+01] vol [5.63184e-11] ncalls [786031] scale [0.1260]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5440] min ESS [13.7127] max ESS [51.0000] average jump [0.0306]\n",
      "[nnest.sampler] [INFO] Step [23800] loglstar [-6.4778e+01] maxlogl [-2.2593e+01] logz [-9.0980e+01] vol [4.61096e-11] ncalls [793754] scale [0.2326]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0091]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1552] validation loss [-0.1603]\n",
      "[nnest.trainer] [INFO] Epoch [89] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [39] validation loss [-0.1617] train time (s) [27.8679]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5200] min ESS [12.8139] max ESS [51.0000] average jump [0.0342]\n",
      "[nnest.sampler] [INFO] Step [24000] loglstar [-6.2148e+01] maxlogl [-2.2593e+01] logz [-8.8670e+01] vol [3.77513e-11] ncalls [801450] scale [0.3418]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5320] min ESS [7.8138] max ESS [51.0000] average jump [0.0276]\n",
      "[nnest.sampler] [INFO] Step [24200] loglstar [-5.9929e+01] maxlogl [-1.8864e+01] logz [-8.6478e+01] vol [3.09082e-11] ncalls [808980] scale [0.2539]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4120] min ESS [10.4309] max ESS [51.0000] average jump [0.0316]\n",
      "[nnest.sampler] [INFO] Step [24400] loglstar [-5.7617e+01] maxlogl [-1.5246e+01] logz [-8.4327e+01] vol [2.53055e-11] ncalls [816758] scale [0.4030]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5200] min ESS [9.8285] max ESS [51.0000] average jump [0.0266]\n",
      "[nnest.sampler] [INFO] Step [24600] loglstar [-5.5749e+01] maxlogl [-1.5246e+01] logz [-8.2486e+01] vol [2.07184e-11] ncalls [824074] scale [0.1939]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5260] min ESS [9.2115] max ESS [51.0000] average jump [0.0295]\n",
      "[nnest.sampler] [INFO] Step [24800] loglstar [-5.3621e+01] maxlogl [-1.5246e+01] logz [-8.0696e+01] vol [1.69628e-11] ncalls [831710] scale [0.2428]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0082]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1663] validation loss [-0.1707]\n",
      "[nnest.trainer] [INFO] Epoch [51] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [1] validation loss [-0.1707] train time (s) [16.0181]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4920] min ESS [9.4254] max ESS [51.0000] average jump [0.0256]\n",
      "[nnest.sampler] [INFO] Step [25000] loglstar [-5.1687e+01] maxlogl [-1.5246e+01] logz [-7.8879e+01] vol [1.38879e-11] ncalls [839167] scale [0.2700]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5440] min ESS [7.8587] max ESS [51.0000] average jump [0.0251]\n",
      "[nnest.sampler] [INFO] Step [25200] loglstar [-5.0052e+01] maxlogl [-1.5246e+01] logz [-7.7280e+01] vol [1.13705e-11] ncalls [846939] scale [0.2971]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5640] min ESS [9.7880] max ESS [51.0000] average jump [0.0258]\n",
      "[nnest.sampler] [INFO] Step [25400] loglstar [-4.8262e+01] maxlogl [-1.5246e+01] logz [-7.5677e+01] vol [9.30937e-12] ncalls [854651] scale [0.1328]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5180] min ESS [9.0419] max ESS [51.0000] average jump [0.0222]\n",
      "[nnest.sampler] [INFO] Step [25600] loglstar [-4.6564e+01] maxlogl [-1.5246e+01] logz [-7.4177e+01] vol [7.62187e-12] ncalls [862329] scale [0.1485]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4940] min ESS [9.9819] max ESS [51.0000] average jump [0.0203]\n",
      "[nnest.sampler] [INFO] Step [25800] loglstar [-4.4785e+01] maxlogl [-1.5246e+01] logz [-7.2613e+01] vol [6.24026e-12] ncalls [870033] scale [0.3932]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0074]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1722] validation loss [-0.1759]\n",
      "[nnest.trainer] [INFO] Epoch [55] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [5] validation loss [-0.1797] train time (s) [17.5115]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5200] min ESS [9.4449] max ESS [51.0000] average jump [0.0299]\n",
      "[nnest.sampler] [INFO] Step [26000] loglstar [-4.3191e+01] maxlogl [-1.5246e+01] logz [-7.1150e+01] vol [5.10909e-12] ncalls [878170] scale [0.2278]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4160] min ESS [16.0475] max ESS [51.0000] average jump [0.0275]\n",
      "[nnest.sampler] [INFO] Step [26200] loglstar [-4.1558e+01] maxlogl [-1.5246e+01] logz [-6.9736e+01] vol [4.18297e-12] ncalls [885847] scale [0.4276]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5300] min ESS [9.7794] max ESS [51.0000] average jump [0.0279]\n",
      "[nnest.sampler] [INFO] Step [26400] loglstar [-4.0167e+01] maxlogl [-1.5246e+01] logz [-6.8420e+01] vol [3.42472e-12] ncalls [893635] scale [0.2927]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5600] min ESS [8.0969] max ESS [51.0000] average jump [0.0194]\n",
      "[nnest.sampler] [INFO] Step [26600] loglstar [-3.8809e+01] maxlogl [-1.5246e+01] logz [-6.7188e+01] vol [2.80393e-12] ncalls [901467] scale [0.1639]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6080] min ESS [9.6026] max ESS [51.0000] average jump [0.0181]\n",
      "[nnest.sampler] [INFO] Step [26800] loglstar [-3.7508e+01] maxlogl [-1.4627e+01] logz [-6.5979e+01] vol [2.29566e-12] ncalls [909285] scale [0.3035]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0068]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1830] validation loss [-0.1873]\n",
      "[nnest.trainer] [INFO] Epoch [65] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [15] validation loss [-0.1887] train time (s) [20.3523]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5520] min ESS [7.0758] max ESS [51.0000] average jump [0.0204]\n",
      "[nnest.sampler] [INFO] Step [27000] loglstar [-3.6293e+01] maxlogl [-1.4627e+01] logz [-6.4929e+01] vol [1.87953e-12] ncalls [916985] scale [0.2672]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5720] min ESS [5.6915] max ESS [51.0000] average jump [0.0258]\n",
      "[nnest.sampler] [INFO] Step [27200] loglstar [-3.5117e+01] maxlogl [-1.2649e+01] logz [-6.3920e+01] vol [1.53883e-12] ncalls [924734] scale [0.4035]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5220] min ESS [10.5670] max ESS [51.0000] average jump [0.0299]\n",
      "[nnest.sampler] [INFO] Step [27400] loglstar [-3.3849e+01] maxlogl [-1.2649e+01] logz [-6.2899e+01] vol [1.25989e-12] ncalls [932424] scale [0.7462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] Acceptance [0.5760] min ESS [7.6070] max ESS [51.0000] average jump [0.0209]\n",
      "[nnest.sampler] [INFO] Step [27600] loglstar [-3.2678e+01] maxlogl [-1.2649e+01] logz [-6.1897e+01] vol [1.03151e-12] ncalls [940238] scale [0.3770]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5400] min ESS [13.4336] max ESS [51.0000] average jump [0.0226]\n",
      "[nnest.sampler] [INFO] Step [27800] loglstar [-3.1568e+01] maxlogl [-1.2570e+01] logz [-6.0929e+01] vol [8.44527e-13] ncalls [948247] scale [0.1450]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0061]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.1952] validation loss [-0.1985]\n",
      "[nnest.trainer] [INFO] Epoch [66] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [16] validation loss [-0.1994] train time (s) [20.7312]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5020] min ESS [8.2556] max ESS [51.0000] average jump [0.0215]\n",
      "[nnest.sampler] [INFO] Step [28000] loglstar [-3.0520e+01] maxlogl [-1.2570e+01] logz [-6.0007e+01] vol [6.91440e-13] ncalls [956030] scale [0.3107]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5640] min ESS [7.9751] max ESS [51.0000] average jump [0.0194]\n",
      "[nnest.sampler] [INFO] Step [28200] loglstar [-2.9405e+01] maxlogl [-1.2570e+01] logz [-5.9113e+01] vol [5.66103e-13] ncalls [964311] scale [0.2426]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4840] min ESS [8.0641] max ESS [23.1107] average jump [0.0190]\n",
      "[nnest.sampler] [INFO] Step [28400] loglstar [-2.8409e+01] maxlogl [-1.2570e+01] logz [-5.8236e+01] vol [4.63486e-13] ncalls [972200] scale [0.1326]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4360] min ESS [7.1047] max ESS [29.9289] average jump [0.0192]\n",
      "[nnest.sampler] [INFO] Step [28600] loglstar [-2.7526e+01] maxlogl [-1.0279e+01] logz [-5.7452e+01] vol [3.79470e-13] ncalls [980098] scale [0.2788]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5220] min ESS [9.4027] max ESS [51.0000] average jump [0.0244]\n",
      "[nnest.sampler] [INFO] Step [28800] loglstar [-2.6617e+01] maxlogl [-8.1849e+00] logz [-5.6720e+01] vol [3.10684e-13] ncalls [987938] scale [0.3712]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0056]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.2035] validation loss [-0.2079]\n",
      "[nnest.trainer] [INFO] Epoch [80] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [30] validation loss [-0.2095] train time (s) [25.3550]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5040] min ESS [4.9395] max ESS [51.0000] average jump [0.0167]\n",
      "[nnest.sampler] [INFO] Step [29000] loglstar [-2.5880e+01] maxlogl [-8.1849e+00] logz [-5.6057e+01] vol [2.54367e-13] ncalls [995814] scale [0.1857]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5620] min ESS [9.9220] max ESS [51.0000] average jump [0.0177]\n",
      "[nnest.sampler] [INFO] Step [29200] loglstar [-2.5012e+01] maxlogl [-8.1849e+00] logz [-5.5402e+01] vol [2.08258e-13] ncalls [1003511] scale [0.2316]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6080] min ESS [7.4893] max ESS [51.0000] average jump [0.0231]\n",
      "[nnest.sampler] [INFO] Step [29400] loglstar [-2.4243e+01] maxlogl [-8.1849e+00] logz [-5.4779e+01] vol [1.70507e-13] ncalls [1011218] scale [0.5363]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5800] min ESS [10.2741] max ESS [51.0000] average jump [0.0200]\n",
      "[nnest.sampler] [INFO] Step [29600] loglstar [-2.3525e+01] maxlogl [-8.1849e+00] logz [-5.4188e+01] vol [1.39599e-13] ncalls [1019095] scale [0.2211]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4680] min ESS [7.7397] max ESS [51.0000] average jump [0.0231]\n",
      "[nnest.sampler] [INFO] Step [29800] loglstar [-2.2920e+01] maxlogl [-8.1849e+00] logz [-5.3647e+01] vol [1.14294e-13] ncalls [1026998] scale [0.2083]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0051]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.2131] validation loss [-0.2174]\n",
      "[nnest.trainer] [INFO] Epoch [53] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [3] validation loss [-0.2193] train time (s) [17.9583]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5360] min ESS [14.5794] max ESS [51.0000] average jump [0.0232]\n",
      "[nnest.sampler] [INFO] Step [30000] loglstar [-2.2316e+01] maxlogl [-8.1849e+00] logz [-5.3158e+01] vol [9.35762e-14] ncalls [1035219] scale [0.2626]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [10.2752] max ESS [51.0000] average jump [0.0158]\n",
      "[nnest.sampler] [INFO] Step [30200] loglstar [-2.1641e+01] maxlogl [-8.1849e+00] logz [-5.2693e+01] vol [7.66137e-14] ncalls [1043166] scale [0.2112]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5800] min ESS [8.1786] max ESS [51.0000] average jump [0.0226]\n",
      "[nnest.sampler] [INFO] Step [30400] loglstar [-2.1068e+01] maxlogl [-8.1849e+00] logz [-5.2243e+01] vol [6.27260e-14] ncalls [1051021] scale [0.2029]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5480] min ESS [5.2731] max ESS [51.0000] average jump [0.0190]\n",
      "[nnest.sampler] [INFO] Step [30600] loglstar [-2.0549e+01] maxlogl [-8.1849e+00] logz [-5.1828e+01] vol [5.13557e-14] ncalls [1059085] scale [0.2818]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5280] min ESS [4.9940] max ESS [51.0000] average jump [0.0181]\n",
      "[nnest.sampler] [INFO] Step [30800] loglstar [-1.9957e+01] maxlogl [-8.1849e+00] logz [-5.1436e+01] vol [4.20465e-14] ncalls [1066984] scale [0.1226]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0047]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.2211] validation loss [-0.2246]\n",
      "[nnest.trainer] [INFO] Epoch [96] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [46] validation loss [-0.2274] train time (s) [30.4684]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5200] min ESS [7.8137] max ESS [51.0000] average jump [0.0255]\n",
      "[nnest.sampler] [INFO] Step [31000] loglstar [-1.9408e+01] maxlogl [-8.1849e+00] logz [-5.1050e+01] vol [3.44248e-14] ncalls [1074878] scale [0.3945]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5900] min ESS [10.5443] max ESS [51.0000] average jump [0.0233]\n",
      "[nnest.sampler] [INFO] Step [31200] loglstar [-1.8881e+01] maxlogl [-8.1849e+00] logz [-5.0678e+01] vol [2.81846e-14] ncalls [1082613] scale [0.5893]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5560] min ESS [8.6744] max ESS [51.0000] average jump [0.0176]\n",
      "[nnest.sampler] [INFO] Step [31400] loglstar [-1.8387e+01] maxlogl [-5.0039e+00] logz [-5.0325e+01] vol [2.30756e-14] ncalls [1090341] scale [0.1600]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6280] min ESS [10.5972] max ESS [51.0000] average jump [0.0176]\n",
      "[nnest.sampler] [INFO] Step [31600] loglstar [-1.7847e+01] maxlogl [-5.0039e+00] logz [-4.9980e+01] vol [1.88927e-14] ncalls [1098063] scale [0.1507]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5540] min ESS [5.3923] max ESS [51.0000] average jump [0.0181]\n",
      "[nnest.sampler] [INFO] Step [31800] loglstar [-1.7355e+01] maxlogl [-5.0039e+00] logz [-4.9639e+01] vol [1.54680e-14] ncalls [1105714] scale [0.2091]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0042]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.2324] validation loss [-0.2366]\n",
      "[nnest.trainer] [INFO] Epoch [73] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [23] validation loss [-0.2396] train time (s) [24.5174]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5080] min ESS [8.8751] max ESS [51.0000] average jump [0.0207]\n",
      "[nnest.sampler] [INFO] Step [32000] loglstar [-1.6905e+01] maxlogl [-5.0039e+00] logz [-4.9325e+01] vol [1.26642e-14] ncalls [1113505] scale [0.2552]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5300] min ESS [6.9718] max ESS [12.1840] average jump [0.0198]\n",
      "[nnest.sampler] [INFO] Step [32200] loglstar [-1.6473e+01] maxlogl [-5.0039e+00] logz [-4.9028e+01] vol [1.03685e-14] ncalls [1121499] scale [0.1290]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5880] min ESS [8.7029] max ESS [51.0000] average jump [0.0189]\n",
      "[nnest.sampler] [INFO] Step [32400] loglstar [-1.6058e+01] maxlogl [-5.0039e+00] logz [-4.8755e+01] vol [8.48904e-15] ncalls [1130063] scale [0.1285]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5400] min ESS [5.9525] max ESS [46.4151] average jump [0.0187]\n",
      "[nnest.sampler] [INFO] Step [32600] loglstar [-1.5609e+01] maxlogl [-5.0039e+00] logz [-4.8485e+01] vol [6.95024e-15] ncalls [1137941] scale [0.2228]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5140] min ESS [19.3637] max ESS [51.0000] average jump [0.0223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.sampler] [INFO] Step [32800] loglstar [-1.5279e+01] maxlogl [-5.0039e+00] logz [-4.8237e+01] vol [5.69038e-15] ncalls [1145886] scale [0.2120]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0038]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.2420] validation loss [-0.2459]\n",
      "[nnest.trainer] [INFO] Epoch [98] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [48] validation loss [-0.2466] train time (s) [33.9361]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5560] min ESS [8.8139] max ESS [51.0000] average jump [0.0237]\n",
      "[nnest.sampler] [INFO] Step [33000] loglstar [-1.4902e+01] maxlogl [-4.4904e+00] logz [-4.8008e+01] vol [4.65889e-15] ncalls [1153854] scale [0.3695]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5500] min ESS [11.0376] max ESS [51.0000] average jump [0.0223]\n",
      "[nnest.sampler] [INFO] Step [33200] loglstar [-1.4543e+01] maxlogl [-4.4904e+00] logz [-4.7794e+01] vol [3.81437e-15] ncalls [1161682] scale [0.1541]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5120] min ESS [8.0412] max ESS [31.2801] average jump [0.0227]\n",
      "[nnest.sampler] [INFO] Step [33400] loglstar [-1.4152e+01] maxlogl [-4.4904e+00] logz [-4.7588e+01] vol [3.12294e-15] ncalls [1169621] scale [0.1960]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5480] min ESS [25.1913] max ESS [51.0000] average jump [0.0233]\n",
      "[nnest.sampler] [INFO] Step [33600] loglstar [-1.3818e+01] maxlogl [-4.4904e+00] logz [-4.7386e+01] vol [2.55685e-15] ncalls [1177425] scale [0.2806]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5220] min ESS [4.4427] max ESS [51.0000] average jump [0.0158]\n",
      "[nnest.sampler] [INFO] Step [33800] loglstar [-1.3445e+01] maxlogl [-4.4904e+00] logz [-4.7195e+01] vol [2.09337e-15] ncalls [1185239] scale [0.2173]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0035]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.2512] validation loss [-0.2566]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.2583] validation loss [-0.2569]\n",
      "[nnest.trainer] [INFO] Epoch [145] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [95] validation loss [-0.2581] train time (s) [48.7421]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5460] min ESS [6.1610] max ESS [51.0000] average jump [0.0235]\n",
      "[nnest.sampler] [INFO] Step [34000] loglstar [-1.3140e+01] maxlogl [-3.3634e+00] logz [-4.7012e+01] vol [1.71391e-15] ncalls [1193210] scale [0.2614]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [18.7886] max ESS [51.0000] average jump [0.0196]\n",
      "[nnest.sampler] [INFO] Step [34200] loglstar [-1.2832e+01] maxlogl [-3.3634e+00] logz [-4.6843e+01] vol [1.40323e-15] ncalls [1200913] scale [0.1015]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4620] min ESS [46.3909] max ESS [51.0000] average jump [0.0215]\n",
      "[nnest.sampler] [INFO] Step [34400] loglstar [-1.2487e+01] maxlogl [-3.3634e+00] logz [-4.6679e+01] vol [1.14887e-15] ncalls [1208787] scale [0.3647]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5740] min ESS [8.8063] max ESS [51.0000] average jump [0.0234]\n",
      "[nnest.sampler] [INFO] Step [34600] loglstar [-1.2162e+01] maxlogl [-3.3634e+00] logz [-4.6519e+01] vol [9.40613e-16] ncalls [1216582] scale [0.1860]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5420] min ESS [12.8344] max ESS [51.0000] average jump [0.0223]\n",
      "[nnest.sampler] [INFO] Step [34800] loglstar [-1.1830e+01] maxlogl [-3.3634e+00] logz [-4.6365e+01] vol [7.70109e-16] ncalls [1224614] scale [0.0958]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0032]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.2613] validation loss [-0.2651]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.2690] validation loss [-0.2680]\n",
      "[nnest.trainer] [INFO] Epoch [125] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [75] validation loss [-0.2694] train time (s) [42.6982]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [10.6779] max ESS [51.0000] average jump [0.0215]\n",
      "[nnest.sampler] [INFO] Step [35000] loglstar [-1.1535e+01] maxlogl [-3.3634e+00] logz [-4.6216e+01] vol [6.30512e-16] ncalls [1232565] scale [0.1457]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5060] min ESS [12.3448] max ESS [51.0000] average jump [0.0219]\n",
      "[nnest.sampler] [INFO] Step [35200] loglstar [-1.1234e+01] maxlogl [-3.3634e+00] logz [-4.6074e+01] vol [5.16219e-16] ncalls [1240388] scale [0.1940]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5600] min ESS [11.9277] max ESS [51.0000] average jump [0.0299]\n",
      "[nnest.sampler] [INFO] Step [35400] loglstar [-1.0933e+01] maxlogl [-3.3634e+00] logz [-4.5938e+01] vol [4.22645e-16] ncalls [1248404] scale [0.2613]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5320] min ESS [6.9092] max ESS [51.0000] average jump [0.0210]\n",
      "[nnest.sampler] [INFO] Step [35600] loglstar [-1.0662e+01] maxlogl [-3.3634e+00] logz [-4.5809e+01] vol [3.46032e-16] ncalls [1256773] scale [0.3310]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5360] min ESS [27.8702] max ESS [51.0000] average jump [0.0293]\n",
      "[nnest.sampler] [INFO] Step [35800] loglstar [-1.0383e+01] maxlogl [-3.3634e+00] logz [-4.5684e+01] vol [2.83307e-16] ncalls [1264710] scale [0.2002]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0029]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.2716] validation loss [-0.2749]\n",
      "[nnest.trainer] [INFO] Epoch [71] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [21] validation loss [-0.2787] train time (s) [23.7386]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5500] min ESS [11.6667] max ESS [51.0000] average jump [0.0296]\n",
      "[nnest.sampler] [INFO] Step [36000] loglstar [-1.0123e+01] maxlogl [-1.7735e+00] logz [-4.5566e+01] vol [2.31952e-16] ncalls [1272751] scale [0.1258]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5380] min ESS [6.3058] max ESS [51.0000] average jump [0.0261]\n",
      "[nnest.sampler] [INFO] Step [36200] loglstar [-9.8408e+00] maxlogl [-1.7735e+00] logz [-4.5454e+01] vol [1.89906e-16] ncalls [1280780] scale [0.3145]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5260] min ESS [24.3185] max ESS [51.0000] average jump [0.0241]\n",
      "[nnest.sampler] [INFO] Step [36400] loglstar [-9.5502e+00] maxlogl [-1.7735e+00] logz [-4.5343e+01] vol [1.55482e-16] ncalls [1288686] scale [0.1925]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5620] min ESS [4.3563] max ESS [51.0000] average jump [0.0242]\n",
      "[nnest.sampler] [INFO] Step [36600] loglstar [-9.2673e+00] maxlogl [-1.7735e+00] logz [-4.5235e+01] vol [1.27298e-16] ncalls [1296673] scale [0.1926]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5700] min ESS [15.6795] max ESS [51.0000] average jump [0.0194]\n",
      "[nnest.sampler] [INFO] Step [36800] loglstar [-8.9645e+00] maxlogl [-1.7735e+00] logz [-4.5128e+01] vol [1.04223e-16] ncalls [1305072] scale [0.1347]\n",
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0026]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.2810] validation loss [-0.2847]\n",
      "[nnest.trainer] [INFO] Epoch [100] train loss [-0.2879] validation loss [-0.2868]\n",
      "[nnest.trainer] [INFO] Epoch [132] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [82] validation loss [-0.2878] train time (s) [44.3686]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5780] min ESS [13.7475] max ESS [51.0000] average jump [0.0230]\n",
      "[nnest.sampler] [INFO] Step [37000] loglstar [-8.7088e+00] maxlogl [-1.7735e+00] logz [-4.5024e+01] vol [8.53305e-17] ncalls [1313236] scale [0.2541]\n",
      "[nnest.sampler] [INFO] Acceptance [0.6060] min ESS [9.8417] max ESS [51.0000] average jump [0.0199]\n",
      "[nnest.sampler] [INFO] Step [37200] loglstar [-8.4759e+00] maxlogl [-1.7735e+00] logz [-4.4926e+01] vol [6.98627e-17] ncalls [1321131] scale [0.1311]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4780] min ESS [16.8601] max ESS [51.0000] average jump [0.0230]\n",
      "[nnest.sampler] [INFO] Step [37400] loglstar [-8.2243e+00] maxlogl [-1.7735e+00] logz [-4.4833e+01] vol [5.71987e-17] ncalls [1329106] scale [0.4717]\n",
      "[nnest.sampler] [INFO] Acceptance [0.4760] min ESS [4.0990] max ESS [51.0000] average jump [0.0159]\n",
      "[nnest.sampler] [INFO] Step [37600] loglstar [-7.9882e+00] maxlogl [-1.7735e+00] logz [-4.4744e+01] vol [4.68304e-17] ncalls [1337148] scale [0.1047]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5280] min ESS [6.0831] max ESS [51.0000] average jump [0.0267]\n",
      "[nnest.sampler] [INFO] Step [37800] loglstar [-7.7588e+00] maxlogl [-1.7735e+00] logz [-4.4660e+01] vol [3.83415e-17] ncalls [1345268] scale [0.2452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nnest.trainer] [INFO] Number of training samples [1000]\n",
      "[nnest.trainer] [INFO] Training jitter [0.0024]\n",
      "[nnest.trainer] [INFO] Epoch [1] train loss [-0.2919] validation loss [-0.2978]\n",
      "[nnest.trainer] [INFO] Epoch [84] ran out of patience\n",
      "[nnest.trainer] [INFO] Best epoch [34] validation loss [-0.2990] train time (s) [32.2350]]\n",
      "[nnest.sampler] [INFO] Acceptance [0.5460] min ESS [2.8388] max ESS [51.0000] average jump [0.0220]\n",
      "[nnest.sampler] [INFO] Step [38000] loglstar [-7.5367e+00] maxlogl [-1.7735e+00] logz [-4.4581e+01] vol [3.13913e-17] ncalls [1353436] scale [0.4301]\n"
     ]
    }
   ],
   "source": [
    "sampler.run(strategy=['rejection_prior', 'mcmc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sampler.logz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MCSamples(samples=sampler.samples, weights=sampler.weights, loglikes=-sampler.loglikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mc.getEffectiveSamples())\n",
    "print(mc.getMargeStats())\n",
    "print(mc.likeStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plots.getSubplotPlotter(width_inch=8)\n",
    "g.triangle_plot(mc, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
